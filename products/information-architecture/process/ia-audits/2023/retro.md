# 2023 IA Audit Retro

## What went well
- Having a weekly check-in with SMEs (Mikki/Beth) together to get feedback in real time
- Found lots of issues to correct, which was the intention
- Got to set some IA standards
- Feel like we have a spreadsheet template now for future audits
- I know we haven't uploaded the spreadsheets yet to GH but excited that we'll have this documentation somewhere!
- 392 pages evaluated, 116 needing some level of changes
- Audit was relatively straightforward to do, it was agreeing on changes that was more difficult

## What went poorly
- Took longer than anticipated to agree on changes
- The spreadsheet was iterated on throughout the audit so could be hard going back to older audits that were organized a little differently
- In implementing changes, sometimes hard to understand what the actual change is based on the note
- Didn't have the best way to document system-wide changes, like to the rates pages
- The longest time was getting feedback from Mikki/Beth


**Action items**
- Export the spreadsheets from Google to Excel and upload them to GH, possibly as one spreadsheet
- Write better notes next year so we understand them when we return to do the work
- Create a global decisions log, possibly within the audit spreadsheet
- Document guidance we learned this round to help with future audits
- Continue to have meetings with SMEs (Mikki/Beth) together
- Look at setting tighter parameters up front for the audit to empower auditors to make decisions and decrease reviews needed (i.e. we are not changing URLs this round, only documenting changes needed)
  
## What ideas do you have
- a11y ride alongs - helpful to have that voice in the review
- Could we get content feedback on the template/implementation process? Did it make sense to them?
- Presentation at monday design hang on changes / Market this work -- roadshow to explain the value
- Screaming frog was very helpful, can we utilize this tool for future audits?
- Could we skip over the Beth/Mikki weekly review next time, and do a larger review at the end of recommended changes?
- Would breaking up the audit in a different way or over time be helpful?
- Determine how we can sync with content on their audits
- Could we do some sort of automated scan for only pages that have had changes to our IA things (H1, url, navs) in the past year?
- Were there any aspects of the audit that likely don't need to be repeated?
- Could we give IAs more autonomy to make decisions and changes next time since now we know what's up?


**Action items**
- Talk with Public Websites and potentially CMS team to determine if there is an automated way pull either all the data/content we want to review or just those that have issues
- Work with CAIA to imrprove internal processes and communication between content and IA - i.e. if a H1 is modified, an IA is looped in to evaluate navigation and entry points
- Remove the "On this page" component from the audit - we will work to get set standards for when to include, and content can review separately
- There should be a lot more autonomy for auditors to make decisions - this round resulted in lots of standards and guidance being figured out which should help

## What value did this work have
- Meeting standards improves the experience and a11y
- Got the opportunity to connect with stakeholders
- Team learned how to work in drupal
- Got to learn about the content auditing process
- Got important context on the hubs/past decisions
- Looked at every page, so we have a better intuitive sense of the site as a whole
- Learned more about SME dynamics and why diff hubs are the way they are
- Reduced cognitive load of some confusing menu terminology
- Got to work more with Beth!
- Created new standard for labels on hub pages to have better experience for ppl navigating links with keyboard
