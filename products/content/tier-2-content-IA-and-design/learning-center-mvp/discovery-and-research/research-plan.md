# Research Plan for Learning Center MVP

-----DRAFT--------

Liz Lantz, Public Websites, June 2020

## Goals	

1. What product & team are you doing this research for?	

   This research is for the Learning Center MVP, Public Websites team.

2. Background: Briefly, what is the background on this product? What would a new person on the team need to know about this product? 	

   When the new VA.gov was launched, a tiered content framework was created to prioritize content transition.  Tier 1 content (benefit content and tools) was brought into the VA.gov site experience first. The Tier 1 migration is nearly complete, and we are beginning to address migrating the tremendous amount of Tier 2, benefit-adjacent content (for beneficiaries, and people who work with beneficiaries).

   The Learning Center MVP is designed to support the following goals:

   - Help Veterans find Tier 2 content in a way that doesn't dilute, distract, and clutter Veterans' benefit top task content and UX.  

   - Increase self-service for Veterans, and those who support them, when they have questions about benefits or need to troubleshoot VA account problems.

   - Reduce calls to the call center and the need for in-person visits to VA locations to answer questions about benefits or to troubleshoot VA account problems.

3. Research questions: What question(s) do you hope to be able to answer after completing this research? 

   - Is the information easy to find using this search-focused, tag-based navigation?
   - Are the template labels (ex: FAQs, Checklist, Media List) useful to users?
   - What do users see as the difference between the learning center and overall site search?
   - Do users get confused if they don't find something in the benefit hub and they have to go to the learning center?
   - Do users understand that information they don't find in the learning center might be in the benefit hub?
   - Where would the most useful place be to provide links to the Learning Center?
   - Is the proposed IA (taxonomy, categorization, labels, nomenclature) effective for Veterans and those who support Veterans?

4. Hypothesis: What is your hypothesis for this research? 	

   - Users will easily understand how to use the search functionality.
   - Template labels will help users determine which search result is most relevant to their search.
   - Users will be unclear about when to use the Learning Center over global site search.
   -  Users won't explicitly differentiate between the benefit hub and the Learning Center; they'll default to using overall site search if they can't find what they're looking for in either place.
   - Our proposed IA will be effective for Veterans and those who support Veterans.

## Method	

1. What method of research are you planning? 	

   We're planning on doing a remote, moderated usability study to answer our first 5 questions (everything but taxonomy and labeling).  We'll ask participants to go through a clickable prototype.

   To evaluate the proposed IA  (taxonomy, categorization, labels, nomenclature), we'll send out a link to a remote, unmoderated card sort.

2. Why this method? How does this methodology help you answer your research questions? 	

   Having participants complete tasks in a clickable prototype will help us understand how easily they're able to find the information they're looking for, and gain insight into how they would go about looking for information they can't find.  The presence of a moderator will allow us to ask follow-up questions and guide the participant through the tasks.

   We've decided to do a card sort to validate our proposed IA because this is a method proven to be successful in determining an organization scheme that best matches users' mental models. These sessions will be unmoderated since we can provide clear instructions through Optimal Sort, and we hope to get responses from a larger participant pool than would be possible with a moderator.

3. Where are you planning to do your research?

   We'll do our research remotely, using Zoom and Optimal Sort.	

4. What will you be testing? *(Design mocks, card sort, prototype, page, content, etc.)* 	

   We'll be testing a clickable prototype, and using a card sort through Optimal Sort.

## Participants and Recruitment	

1.	We'd like to interview 8 Veterans
   - Participants must be able to participate via a desktop device.
   - **Do we need criteria related to the content we'll be showing? E.g. having an account, familiar with burial benefits, or disability benefits?**
   - We request the participant pool be diverse in:
     - Gender (ideally 4 women, 4 men)
     - Ethnicity/Race (at least 4 non-Caucasian)
     - Age. Ideally, we will have 
       - 2 people from 18-24
       - 2 people from 25-34
       - 2 people from 35-54
       - 2 people who are 55 or older.
     - Education level (at least 2 falling somewhere between "some high school" and "some college" on their response to "Highest Level of Education" question on registration form)
     - Geography
   - To ensure inclusivity, we request at least one participant that has identified cognitive impairments and/or functional disabilities. Diagnoses that may align with this would be Traumatic Brain Injury (TBI), Post-Traumatic Stress Disorder (PTSD), Attention-Deficit/Hyperactivity Disorder (ADHD), Autism, and Vertigo. Other conditions may be autism, aphasia, dyslexia, dyscalculia, distractibility, memory loss, reading difficulties, non-native English speakers, low tolerance for cognitive overload, and intellectual/adaptive functioning challenges such as learning and problem-solving.

**2. What is your recruitment strategy?**

- For usability study:
  - We will leverage Perigan's recruitment capabilities
  - In order to get 8 participants, we'd like Perigean to recruit 12, with the expectation that there be a max of 4 no shows.
  - We'll ask to cancel any remaining sessions once we hit 8. 
- For our card sort, we'll send the link out **NEED TO REFINE THIS**

## When? 	

1. Timeline: What dates do you plan to do research? 	
   July 7-9, 2020

2. Prepare: When will the thing you are testing be ready? 

   July 2, 2020

3. Length of Sessions: How long do you estimate each session will be? 

   30 minutes

4. Availability: If applicable, when would you like sessions scheduled? **Please list exact dates and times in EASTERN Standard Time**. 

   Please allow 30 minutes between sessions

   - July 7:

   - July 8: 

   - July 9:  	

5. Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 	

   July 6, Nick Sullivan or Kelson Adams

## Team Roles	

Please list the people who will be serving in each role. **Include the primary phone number for moderator and the emails for moderator, notetaker, and observers. If you need Perigean to take notes for you, indicate that next to Notetaker** 	

- Moderator: Liz Lantz, 843-898-4463, liz.lantz@adhocteam.us

- Research guide writing and task development (usually but not always same as moderator): Liz Lantz

- Participant recruiting & screening: Perigean 

- Project point of contact: Liz Lantz

- Participant(s) for pilot test:	

- Note-takers:	

- Observers:	

  - Jen Lee (jennifer.lee27@va.gov)

  - Ryan Thurlwell (Ryan.Thurlwell@va.gov)

  - Danielle Thierry (danielle.thierry@va.gov)

  - Beth Potts (beth.potts@va.gov)

  - John Hashimoto ()

  - Kelson Adams ()

  - Oksana Cyrwus

  - Kevin Walsh

  - Laura Walsh

  - Nick Sullivan (nick.sullivan@adhoc.team)

  - Randi Hecht

  - Mikki Northuis

  - Selina Cooper

  - Anne Hurley

  - Steve Wirt

    

## Resources	

- [Product Outline](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/tier-2-content-IA-and-design/learning-center-mvp/product-outline.md) 
- Convo Guide - coming soon
- Prototype to be tested - coming soon
- Card sort - coming soon
- Synthesis - coming soon
- Lessons Learned - coming soon	
- Read-Out/Results  - coming soon
