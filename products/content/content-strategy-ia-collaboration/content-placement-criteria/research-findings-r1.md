# Research findings for Sitewide Content and IA - Benefit content placement criteria

**Danielle Thierry, Mikki Northuis**

View the [Research Plan](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/content-strategy-ia-collaboration/content-placement-criteria/research-plan-r1.md).

## Research Goals 

We want to understand if the content placement criteria helps content authors feel confident in making quicker decisions of where to place content in the modernized VA.gov environment.


## Research Methodology 

A group session was held with 4 members of the Sitewide Content and IA team and 1 content designer from CMS.  
The participants completed an activity individually, and then everyone regrouped for a moderated discussion. 


### Who we talked to

Description of who was spoken to.

### Research Questions

Research questions we looked to answer: 
- Is the concept of this criteria a helpful tool in determining where to place content on VA.gov?
- Are the placement criteria clear and understandable?
- Are the placement criteria effective in determining placement of content?
- Are there any gaps in the placement criteria that result in the inability to make a decision on content placement?


## Findings

**1. Content authors found the criteria to be helpful and easy to use, and helped decision making confidence.**
- After the activity, the participants were asked to rate the criteria on helpfulness, ease of understanding, and decision confidence on a scale of 1-5, 1 being the lowest score and 5 being highest.
  - Ease of use averaged 4.4
  - Helpfulness of criteria averaged 4.2
  - Confidence in decisions averaged 4.4
- In addition, the group indicated that having the criteria would be useful in supporting and explaining decisions to stakeholders
  - _"Just the fact that weâ€™d have something to point to would be incredibly helpful."_
- For baseline purposes, the group was able to evaluate 5 pages of varying length within 30-35 minutes


**2. Placement decisions, although consistent within the group, did not generally match our SME placement decisions**
- Only 2 of the 5 pages evaluated had a majority placement decision that matched the SME results
- The group heavily leaned towards benefit hub placement, while the SME decision only placed 1 page entirely in the benefit hubs
  - A majority of the group placed 4/5 pages in the benefit hub and 1 page in R&S
  - Our SME placed only 1 page entirely in the benefit hub, with another 2 pages split between the hub and R&S; The remaining 2 pages were placed in R&S
- Placement decisions within the group were relatively consistent, and provided some good insight into how they interpreted the criteria and looked at the content they were given - this is further explored in findings 3-5
  - Three of the pages evaluated (clothing allowance, PTSD and Camp Lejeune) had full agreement for benefit hub placement
  - The other two pages (Agent Orange and dental care) had a majority agreement for placement - 3/5 participants placed the Agent Orange page within the benefit hub, and 3/5 placed the dental care page in R&S


**3. The language used in criteria 3 around "unique application or application process" and "core or supplemental benefit" was not clear to the group**
- There was not agreement on what the difference between "core" and "supplemental" meant
  - On participant felt that if there's a specific application or form to fill out, it's supplemental, this included if they have to fill out the main benefit form a second time. 
  - Another participant wondered if "core" referred to what everyone receives, where as "supplemental" is based on unique circumstances
  - When the group was asked if they agreed with any of the definitions given, besides a slight head nod from one person, the group did not really provide a response back in agreement or disagreement.
  - _"...I did spend a lot of time on the core vs. supplemental. I don't know why I struggled with it because it didn't say you had to do anything different for the them, but I think I know enough to be dangerous and found myself thinking that those terms are important and wanting to define them."_
- Participants also noted that when content referenced any application or form, they often answered "yes" to this criteria, and the word "unique" didn't seem to play a part
  - _"I was looking for is there an application there, is there a link to an application"_ 
- In addition, there was uncertainty around what was included in "application process" 
    -  _"...thinking "application process"...does that include additional evidence that's way more extensive than what would often be required? I took it not to mean evidence."_  
    -  _"for the process, does that mean what you have to do in the form, or things you need to get ready to do the application...getting ready to, plus doing the thing, plus the afer"_

**4. Even though they made a single placement decision for each page, they often indentified sections of content in a page they considered for separate placement**
- Although most pages resulted in an overall placement in the benefit hubs, everyone in the group identified some piece of content that they considered a better fit for R&S
  - _"You could take out the question "What's an Agent Orange exam, and how do I request one?" and move that to Resources and support since it's not a requirement for the Veteran to receive disability benefits."
  - _"this might be one of those pages that's a split...some of it goes in the benefit hubs and some of it goes in R&S"_


**5. Individual biases and experience of the person doing the evaluation played a part in making the decision**
- Existing knowledge and biases of what is considered a benefit, and where benefit content should be placed, played a part in decision making (i.e. "tier 1", veteran-facing content)
  - _"I'm not sure that extra content belongs in R&S, maybe another hub page would be better, because I still feel like it's tier 1 because it's for Veterans."_
- Many members of the group cited times where they would revise a heading, restructure the content, or elaborate on content in order to build out a better page. Doing this would occassionally lead them to making a different decision.
- Despite criteria answers resulting in a R&S placement for the Dental health page for the entire group, the majority of them expressed some level of disagreement with it.  
  - _"It's written like it's trying to convince you that it's R&S, but the more you look at it, it feels like benefit hub."_
  - _"I put in R&S as it is now, but would go to benefit hub if you took info from the linked fact sheet and how to apply for it"_
  
**6. The layout and format of the worksheet could use some minor improvements**
- Not everyone was clear that if you answered "yes" to criteria 4, the decision was made and you did not need to go on to the last criteria.  
  - _"I went on to # 5 every time, even though I answered "yes" to the fourth one"_

## Recommendations

**Revise the language used in criteria 3 to be more understandable**
- Clarify what is included in "application process"
- The terms "core" versus "supplemental" need to be defined, as well as indicate how they impact the placement decision
- Consider splitting this criteria to clarify the dependency between the two scenarios

**Revise how the criteria is presented to make them easier to scan and read**
- The group liked how criteria #5 used bullets to list out the individual scenarios and suggested the same formatting be followed for criteria 2 and 3. 
- Make it very clear that criteri 5 is only used for content planned for placement within R&S

**Include guidance on how to evaluate content with the criteria**
- Providing guidance on how to evaluate content against the criteria could help authors in making better placement decisions.
- This guidance could include information such as
  -  Examples of content and how it meets or does not meet criteria
  -  Assitance on how evaluate sections of content versus the whole page/document

**Establish governance process to help catch placement decisions that may not be correct prior to publishing**
- Having an overall governance process would not only help catch incorrect placement decisions, but also create an opportunity to continue to educate authors on the placement criteria. 


## Next Steps


- Update criteria 3 based on feedback
- Create instructions and guidance for content authors on how to use the critera 
- Utilize the revised criteria in the R&S pilot with the Community Care working group to further validate

## Appendix
### Conversation guide
- [Conversation guide](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/content-strategy-ia-collaboration/content-placement-criteria/research-conversation-guide-r1.md)

### Interview transcripts
- [Notes](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/content-strategy-ia-collaboration/content-placement-criteria/criteria-test-internal-notes.md)

### Tools used for Synthesis
- [Session notes ](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/content-strategy-ia-collaboration/content-placement-criteria/criteria-test-internal-notes.md)

### Other supporting documents created
- [research-criteria-worksheet-combined-answers.xlsx](https://github.com/department-of-veterans-affairs/va.gov-team/files/8248496/research-criteria-worksheet-combined-answers.xlsx)
- [research-test-content.docx](https://github.com/department-of-veterans-affairs/va.gov-team/files/8248497/research-test-content.docx)



