Sync between John Hashimoto and Nick Sullivan

### Schema.org history
On Vets.gov, schema.org was implemented heavily throughout our static content files on GitHub. 
It was always unclear how beneficial this was, and if it was actually bringing traffic to the site. When we migrated our content
from GitHub to Drupal, we didn't implement schema.org into the Drupal templates. We attempted an experiment to gauge whether
we should by adding schema.org into a few pages, but we couldn't produce a schema.org widget on Google.com for us to evaluate effect.


### Sitemap
- We currently generate our sitemap during every deployment - www.va.gov/sitemap.xml
    - This includes all of our modernized content, primarily pages from Drupal
    - This sitemap.xml is basically a reflection of Drupal (like an index page)
- Search.gov currently has the expectation that we will provide a sitemap for other VA subdomains based on a sync on the search tool back in 2018
    -  The way we currently generate our sitemap.xml is technically very simple and very easy. It also achieves our high-level objective of giving extra weight to our modernized content (Drupal)
    - VA subdomains or pages that are not part of modernized UX
         - Sitemap - we don't have the technical ability to produce a sitemap.xml because those pages are not part of our infrastructure
         - Most ideally the domain owners could produce the sitemap.xml dynamically
         - If they can't, we'd have to do it manually by compiling the URLs or by crawling, which is not ideal
             - We probably wouldn't want to do this because it would be effectively the same as Search.gov issuing a crawl
         - Do we even want to give extra weight (via a sitemap.xml) to these non-modernized pages/domains? What's the motivation for this?
             - Some subdomains like benefits.va.gov are still importants, and one motive is to update metadata in search results sooner.

Context and history from Jen Lee:
When va.gov launched, the Merger/WBC team purposefully suppressed indexing of subdomain urls. This was partly bc those subdomains have/had such huge historic domain authority and  search ranking, and we wanted to make sure that the modern pages were coming up at least in internal searches.

Many of the modern pages now have organic search ranking and over time will get more as we retire more of the legacy pages, so at some point it will probably make sense to turn that back on. Will defer to @John Hashimoto  to think that through as you're working on site search strategy, but wanted you to know the business reason behind the current state.



__Question__: If we knew of a technical method to do it, would we want to produce a sitemap for non-modernized areas of VA.gov? This may add extra SEO weight to those pages.

### Additional Search features
- Type-ahead
    - Basically ready for immediate implementation
- Routed queries
    - API doc coming
    - One of the top search is 
- Additional potential - images, videos, Twitter feed, jobs - we can be imaginative with our UX
