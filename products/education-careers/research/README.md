# Research Plan for Education End-to-End Experience, VA.gov, June 2019
## Goals

1. What product and team: This is discovery research meant to inform experience guidelines, overall Education hub information architecture, and products (education benefit forms, including GI Bill, GI Bill Feedback, Comparison Tool, Eligibility Wizard, VetTech form, STEM form) associated with researching and applying for education benefits from the Veterans Benefits Administration. It will support our relationship with Edu services stakeholders, as well as supporting the Booz Allen Hamilton team tasked with working on specific Edu products, and help develop future experience initiatives. 
2. Background: Veterans and other beneficiaries of the GI Bill want  to learn about and apply for benefits. The current user experience on VA.gov does not take a strong position between the goal of “learning about” and the goal of “applying,” although it tends to lean towards applying, assuming the user already has detailed knowledge of what benefit they are the most interested in applying for. Existing content and functionality supporting Veteran and other constituencies’ ability to learn about the GI bill, assess which benefits apply to them, determine eligibility, and research schools are widely distributed across VA.gov, a few specific software products and applications, and legacy sites and software (such as  [eBenefits.va.gov](http://ebenefits.va.gov/) ,  [benefits.va.gov](http://benefits.va.gov/) ,  [gibill.custhelp.va.gov](http://gibill.custhelp.va.gov/) , and more). 
3. Research questions: How do Veterans and service members orient themselves to information about educational benefit programs? Among existing transition programs (e.g. the TAP program), official VA materials, non-official VA materials (military.com), and personal networks (peers, friends, family, and colleagues) what is trusted? Why or why not? What works? Why or why not? 
4. Hypotheses: 
* Official military and VA materials do not do a sufficient job of providing sufficient context for users to feel confident. 
* Human beings play a greater role than digital content in supporting educational planning and decision making. 
* Content available via both official and non-official channels does not successfully convey the changes in programs that have taken place since the Colmery Act. 

## Method

1. Remote moderated ethnographic interviews combined with open (not directed) usability testing of existing websites and tools, both official and non-official. In person field research journey map interviews with school certifying officials (SCOs) to flesh out the process. 

2. Why this method? How does this methodology help you answer your research questions? 

This combination of methods will allow us to illustrate the process as it exists and more clearly define the pain points for improving the user experience for education benefit research and discovery, early in the journey. 

3. Where are you planning to do your research? If in person, mention the location, point of contact, arrangements, etc. If online, mention which tool you’ll be using (GTM, Join.me, etc.)

I’d like to use a remote recording tool for interviews with service members and Veterans, and I’d like to do in person interviews with SCOs at Philadelphia and Washington DC area universities, including Temple, Drexel, U Penn, Philadelphia University, and any others that we can find. 

4. What will you be testing? (Design mocks, card sort, prototype, page, content, etc.) 

This is primarily not meant to be a usability test, however in the research, we’ll observe people using both VA.gov and any other tools that they normally use in their research and discovery. If they haven’t done any research and discovery yet, we’ll observe what they would do. 

### Participants and Recruitment

1. Participant criteria: What are you looking for in a participant?
(Mention: Number of people, ages, accessibility preferences, geographical diversity, login requirements, VA benefit requirements, familiarity with technology, etc. Keep in mind, the more requirements, the more difficult the recruit, so give ample time to ensure the right participant mix.)
* 10 veterans who have transitioned out of service 
	* 5 considering using their education benefits that have not yet applied
	* 5 that have recently applied and are using the benefits (past 2 years)
* 10 service members 
	* 5 considering using their education benefits who have not yet applied
	* 5 that have recently applied and are using benefits (past 2 years)
* 10 SCOs in the Philadelphia area (139 results in comparison tool) or DC area (12 results) - not the responsibility of Perigiean 

2. What is your recruitment strategy? 
(If in person, describe how you will find participants. If remote, mention if you plan to draw from the existing recruiting contract or if there are other places where you would like to reach out to find participants specifically for this project. If you need help, please contact UX lead.)

Happy to use existing recruitment processes for Vets, and school point of contacts through Edu services. 

### When? 

1. Timeline: What dates do you plan to do research? 
(IF you are using the research recruiting contract, please submit 1 FULL week prior to the start of research for remote, 2+ weeks for in person.) 

* Philadelphia school research - week of July 8 
* All other research - interviews starting July 8, concluding July 15

2. Prepare: When will the thing you are testing be ready? (Goes without saying, but should be a few days before testing will begin.) 

Script is completed and in the folder. 

3. Length of Sessions: How long do you estimate each session will be? (This helps with scheduling & thank you gifts.) e.g. 30 minutes, < 1 hour, up to 2 hours, up to 4 hours) 

1 hour

4. Availability: If applicable, when would you like sessions scheduled? Please list exact dates and times in EASTERN Standard Time. Please request enough dates and time slots (e.g. Monday 9-1, 3-6; Tuesday 9-6, etc.). Be as flexible as possible, cognizant that many Veterans are only available before and after working times, and live across the U.S.

Vet Recruiting Times

* Monday July 8, 7am, 4pm, 5pm, 6pm ET
* Tuesday July 9, 6pm, 7pm ET
* Wednesday July 10, 7am, 9am, 10am, 11am, 5pm, 6pm, 7pm ET
* Friday, July 12, 7am, 9am, 10am, 11am, 1pm, 2pm, 3pm ET
* Monday, July 15, 5pm, 6pm, 7pm ET


5. Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 

Looking for volunteers! I’d love to run a pilot no later than Wednesday, July 3. 

### Team Roles

Please list the people who will be serving in each role. Include the primary phone number for moderator and the emails for moderator, notetaker, and observers. 
- Moderator: Kevin M. Hoffman
- Research guide writing and task development (usually but not always same as moderator): Kevin M. Hoffman
- Participant recruiting & screening: Kevin M. Hoffman with help from 
- Project point of contact: Kevin M. Hoffman
- Participant(s) for pilot test:  Does this need to be 
- Note-takers:  If I record and transcribe without PII, is this necessary? 
- Observers:  Anyone is welcome, might include Matt Self, edu folks, BAH folks. 

List email addresses for those who should attend and observe the sessions: VA Stakeholders, engineering team members, design team members, any other people who might find this research relevant to their work

Matt Self
Lucas Tickner
Shay Norton-Leonard
Stephanie Price
Ricardo Da Salva
Amy Knox
Eddie Ricks
(Additional people will be added as necessary)
