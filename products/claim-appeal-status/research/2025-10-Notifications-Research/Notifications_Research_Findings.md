---
title: "Benefits Management Notifications Study Research Findings"
product: "VA Benefits Management Notifications"
team: "Benefits Management Tools (BMT)"
office: "Office of the CTO - Digital Experience (OCTO-DE)"
date: "2025-12-19"
researchers: 
  - "Naomi Howe"
  - "Melissa Lefevre"
research_goals:
  - "Identify what information participants expect and find most useful in decision letter and evidence request notifications."
  - "Explore which channels participants prefer and why for receiving decision letter and evidence request notifications."
  - "Assess how content structure, tone, and sequencing influence understanding, trust, and task completion."
  - "Explore barriers, trust, and accessibility issues across device types and literacy levels."
methodology:
  - "Semi-structured interviews"
devices_used:
    desktop: 6
    tablet: 1
    smartphone: 4
    assistive_technology: 0
participants_total: 11
demographics:
  veterans: 11
  service_members:  0
  caregivers: 0
  dependents: 0
  VA_staff: 0
  age: 
    "25-34":  1
    "35-44":  2
    "45-54":  2
    "55-64":  2
    "65+": 4
    unknown: 0
  education: 
    high_school: 0
    some_college: 0
    associates: 0
    bachelors: 0
    masters: 0
    doctorate: 0
    unknown: 0
    # All report "some college or higher" (11), but does not specify levels, so this is left in unknown.
  location: 
    urban: 6
    rural:  5
    unknown: 0
  race:
    white: 0
    black: 0
    hispanic: 0
    biracial: 0
    asian: 0
    native: 0
    # Not specified; underserved groups missing include Hispanic/Latino, Native Hawaiian/Pacific Islander, etc.
  disability:
    cognitive: 0
    AT_beginner: 0
    AT_advanced: 0
    screen_reader_desktop: 0
    screen_reader_mobile: 0
   
---
# Benefits Management Notifications Research Findings

**Office of the CTO – Digital Experience (OCTO-DE)**  
**Benefits Management Tools (BMT) – Notifications, Benefits & Claims Notifications (OCTO-DE)**  
**Date:** 12/19/2025  
**Contacts:** Naomi Howe, Melissa Lefevre  

---

## Jump to
- [Hypotheses and Conclusions](#hypotheses-and-conclusions)
- [Key Findings](#key-findings)
- [Recommendations](#recommendations)
- [Product User and Business Outcomes](#product-user-and-business-outcomes)
- [Key Performance Indicators](#key-performance-indicators)
- [Next Steps](#next-steps)
- [Further Research Needed](#further-research-needed)
- [Appendix](#appendix)

---

## Research Goals and Questions

### Goal 1: Identify what information participants expect and find most useful
- How do claimants interpret the purpose and importance of decision letter and evidence request notifications?
- How can future notification design patterns differentiate **informational** vs. **action-required** messages clearly and consistently?
- What is claimant interest in receiving regular notifications about claim status?

### Goal 2: Explore which channels participants prefer and why
- Through which channels do claimants prefer to receive decision-letter vs. evidence-request notifications?
- What factors influence which channel they act on first when messages arrive across multiple channels?
- What perceived risks or harms arise when sensitive, urgent, or complex claim information is sent through different channels (e.g., SMS, email, push)?

### Goal 3: Assess how content structure, tone, and sequencing influence understanding, trust, and task completion
- How do claimants perceive the appropriate level of detail, tone, urgency, and next-step guidance across different channels?
- What sequencing (e.g., text → email → push) best supports timely understanding and action for evidence requests?
- How do message elements (e.g., subject line, sender name, preview text) affect trust and engagement?

### Goal 4: Explore barriers, trust, and accessibility issues
- How do claimants perceive the trade-off between privacy protection and notification specificity?
- How do device usage patterns and digital literacy levels across Veteran segments influence their ability to engage with notifications?

---

## Methodology

We conducted semi-structured, remote interviews via Zoom where participants reviewed static notification samples (email, text, and push messages) for decision letters and evidence requests. Participants examined the messages in Figma through screen sharing and provided feedback on clarity, tone, trustworthiness, and what actions they believed they should take.

The study focused on **message comprehension**, not task completion or usability.

Each session followed a structured format:
1. Warm-up  
2. Decision letter scenario review  
3. Evidence request scenario review  
4. Comparative reflection  

**Artifacts:**  
- Figma prototypes: Desktop & Mobile  

---

## Hypotheses and Conclusions

### Hypothesis 1
**Claimants vary in their channel preference, with many preferring email for official, detailed updates and text messages for urgent or time-sensitive alerts.**  
**Conclusion:** True  

**Evidence:**  
Many participants reviewed notifications on phone (text/push) first but completed actions on desktop or via app. Several preferred email for reading decision letters and text/push for urgent evidence requests (e.g., P4, P8, P10, P17).

---

### Hypothesis 2
**The clarity of the call-to-action (what happened, what to do, and by when) significantly impacts task completion.**  
**Conclusion:** True  

**Evidence:**  
Participants found messaging straightforward but often lacked clarity on deadlines.

- P1: “very straightforward”  
- P5: “I’m gonna log in and find out what it’s about.”  
- P6: “It would be helpful if it said what they were looking for, why, and how soon they need it.”  
- P10: “It should say it’s time sensitive.”

---

### Hypothesis 3
**Friendly and plain language builds trust, while legal or bureaucratic tones create confusion and anxiety.**  
**Conclusion:** True  

**Evidence:**  
Participants praised clear, “cut and dried” wording and bold emphasis. Vague language reduced urgency.

---

### Hypothesis 4
**Privacy concerns about text messages vary depending on content sensitivity (e.g., health vs. compensation updates).**  
**Conclusion:** Definitely true  

**Evidence:**  
Participants appreciated limited personal detail to reduce privacy risk.

---

## Key Findings

- VA messages often feel urgent; clear deadlines make them actionable.
- Trust in VA notifications varies by channel and familiarity.
- Consistent VA branding and digital identifiers are essential.
- Participants prefer navigating directly to VA.gov or the app.
- Multi-channel delivery is welcomed, especially for action-required items.
- Participants often switch from mobile to desktop for complex tasks.
- Confusion persists around notification management and SMS opt-out.
- Communication clarity is strong across channels.
- Preferences are split on claim status notification frequency.
- Notifications included an appropriate level of detail for privacy concerns.

---

## Details of Findings

### Finding 1 — VA messages often feel urgent; clear deadlines make them actionable
Participants want explicit due dates and urgency cues.

> “It should say it’s time sensitive.” — P10  
> “There’s no due date… I have to click the link to find out.” — P4  

---

### Finding 2 — Trust in VA notifications varies by channel and familiarity
Email is most trusted; text links raise scam concerns.

> “I’m not going to click that link… I rarely click links on texts.” — P1  

---

### Finding 3 — Consistent VA branding and digital identifiers are essential
Participants look for .gov domains, letterhead, logos, and familiar short codes.

> “It’s a .gov email… that makes it legitimate.” — P1  

---

### Finding 4 — Participants prefer navigating directly to VA.gov or the app
Many authenticate independently instead of clicking links.

- **Count:** 5/11 preferred logging in directly  

---

### Finding 5 — Multi-channel delivery is welcomed
Especially for action-required notifications.

> “Please send it on all channels… I don’t want to miss that.” — P1  

---

### Finding 6 — Participants switch from mobile to desktop
Mobile for awareness; desktop for completion.

---

### Finding 7 — Confusion persists around notification management and SMS opt-out
Participants are unsure what opting out affects.

> “I’d be hesitant to reply STOP…” — P4  

---

### Finding 8 — Communication clarity is strong across channels
- Decision letters: 100% clarity (text/email), 91% (push)
- Evidence requests: clarity drops due to missing deadlines

---

### Finding 9 — Preferences split on claim status notification frequency
Some want reassurance; others prefer updates only on movement.

---

### Finding 10 — Appropriate level of detail for privacy concerns
Participants prefer general notifications with details behind authentication.

---

## Recommendations

1. **Urgency & Deadlines**
   - Always include explicit due dates.
   - Differentiate informational vs. action-required messages clearly.

2. **Navigation & Verification**
   - Offer clear URLs and encourage direct navigation to VA.gov.

3. **Opt-In / Opt-Out & Channel Management**
   - Provide channel-specific instructions and clearer documentation.

4. **Branding & Trust Cues**
   - Ensure consistent VA branding across all notifications.

5. **SMS & Push Notification Security**
   - Strengthen sender recognition and educate users on authenticity.

6. **Multi-Channel Delivery**
   - Default to multi-channel for critical notifications.

7. **User Preferences & Personalization**
   - Allow customization of notification frequency and triggers.

8. **Privacy & Sensitive Communications**
   - Enable selective channel opt-in for sensitive content.

9. **Cross-Device Experience**
   - Support seamless transitions between mobile and desktop.

10. **Template Improvements**
    - Revise evidence request templates using decision letters as models.

---

## Product User and Business Outcomes

### Desired User Outcome
Veterans clearly understand what happened, what to do, and by when—acting confidently across trusted channels.

### Desired Business Outcome
Improved consistency and trust in notifications, reduced delays in evidence submission, and alignment with OCTO-DE priorities.

---

## Key Performance Indicators

- **Time-to-action for evidence requests**  
  Measure reduced time from notification to submission via VA.gov/app analytics.

---

## Next Steps

- **Content design update (High):** Add due dates and “Action needed” cues.
- **Preference management (Med):** Clarify opt-in/out behavior in VA.gov/app.
- **Create GitHub issues:** Convert recommendations into actionable items.

---

## Further Research Needed

- Validate accessibility with screen readers and magnification.
- Explore comprehension with low-literacy and paper-first Veterans.
- Quantify optimal reminder cadence.
- Clarify opt-out and re-enrollment mental models.

---

## Appendix

### Research Documents
- Product outline  
- Research plan  
- Conversation guide (Notifications)  
- Figma prototypes: Desktop & Mobile  
- Notetaking sheet  

---

## Research Participants

### Recruitment Criteria
- U.S. claimant using VA.gov or VA Health and Benefits app
- Submitted/tracked a claim in the past year
- Received a VA notification within 2 years

### Demographics Summary
- **Participants:** 11  
- **Devices:** Desktop (6), Tablet (1), Smartphone (4)  
- **Age:** 25–34 (1), 35–44 (2), 45–54 (2), 55–64 (2), 65+ (4)  
- **Education:** Some college or higher (11)  
- **Geography:** Urban (6), Rural (5)

### Underserved Groups Not Included
- Other than honorable
- Immigrant origin
- Women
- Expat
- Hispanic/Latino
- Native Hawaiian or Pacific Islander
- LGBTQ+
- All Assistive Technology users
