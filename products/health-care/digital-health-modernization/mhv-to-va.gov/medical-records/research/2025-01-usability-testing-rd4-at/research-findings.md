# Medical Records on VA.gov Usability Study Round 4 (AT) Research Findings

January – February 2025

Melissa Stern

[Research readout](https://github.com/department-of-veterans-affairs/va.gov-team/blob/60752fdb5b41075621b221a69770f537cdafaf7b/products/health-care/digital-health-modernization/mhv-to-va.gov/medical-records/research/2025-01-usability-testing-rd4-at/MR4_Readout.pdf)

## Research Goals

1. Identify any usability issues AT-dependent Veterans may experience in understanding their Medical Records Settings, Microbiology, Pathology, and Radiology Results, Vitals, Allergies, and Download your medical record.  
2. Understand AT-dependent Veterans’ needs and expectations within Medical Records.

## Research Questions

1. Can Veterans who use assistive technology find the information they need to manage their healthcare related to:
    - Medical Records Settings
    - Microbiology, Pathology, and Radiology Results
    - Vitals
    - Care Summaries and Notes
    - Allergies
    - Download your medical records
2. What are Veterans’ reactions to the new experience in which they review their records on screen?
3. What are the goals, expectations, and experiences within Medical Records for Veterans who use assistive technologies?

## Methodology

We conducted moderated usability testing sessions in which we asked participants to navigate a live environment while we observed their behavior, and asked follow-up prompts as needed.

## Hypotheses and Conclusions

_Hypothesis 1:_ Most Veterans who use assistive technology will be able to access and understand information about their medical records to manage their health.

TRUE: Most Veterans who use assistive technology were able to access and understand the various medical records.

_Hypothesis 2:_ Most Veterans who use assistive technology will have positive reactions to the new experience in which they access their records on screen.

TRUE: Most Veterans rated their experiences in the various domains as positive and rated the Medical Records Settings and Lab and Test Results an average of score of “neither difficult nor easy.”

## Key Findings

1. Most participants struggled to understand information pertaining to Medical Records Settings.
    1. About half of the participants (5 of 11) misunderstood how the test user’s medical records were currently being shared.
    2. Most participants (9 of 11) successfully opted the test user into sharing.
    3. All participants (11 of 11) expected additional steps to share their records with individual recipients after opting into sharing.
    4. Most participants (10 of 11) misunderstood what medical information would be shared with providers after opting in or preferred to select what medical information would be shared.
    5. Many participants (4 of 11) tried to access their medical records settings by clicking “Go to your profile on the My HealtheVet website.”
2. Few participants confidently identified microbiology and pathology results, but almost all participants easily located imaging results.
    1. About half of the participants (5 of 11) successfully identified a microbiology test result when asked to find results from an E. coli test.
    2. About half of participants (6 of 11) successfully identified a pathology test result when asked to find results from a biopsy.
    3. Most participants (10 of 11) successfully identified an X-Ray result.
    4. About half of the participants (6 of 11) felt it was useful to have direct access to imaging results in their medical records.
3. All participants (11 of 11) easily identified the test user’s most recent blood pressure, and most participants (10 of 11) found a blood pressure result from several years ago.
4. All participants (11 of 11) easily identified two notes when given only the note titles.
5. All participants (11 of 11) easily identified an allergy record.
6. Few participants (3 of 11) independently found where to download the past three months of lab and test results from the Medical Records landing page.
    1. Most participants (8 of 11) expected to access Blue Button functionality from within the individual domains.
    2. Most participants (8 of 10) successfully made it through the download process after they were directed to the correct page.
7. Most participants on average rated the Medical Records Settings and Lab and Test Results tasks as “neither difficult nor easy,” but rated the Vitals, Care Summaries and Notes, Allergies, and Download your Medical Records Reports tasks as “easy” or “very easy.”
8. Dropdown options are not announced by screen readers when navigated using only the cursor.

## Details of Findings

**Finding 1: Most participants struggled to understand information pertaining to Medical Records Settings.**

When asked how the test user, Pat, was sharing their medical records based on current settings, 5 of 11 participants answered incorrectly or were unsure. As participants progressed through additional tasks within the Medical Records Settings domain, it became evident that their confusion was tied to difficulties in understanding the content and meaning of the settings.

When asked what Pat would have to do to share their records with the CVS Minute Clinic, 9 of 11 participants successfully opted Pat in to sharing with VA partners. However, all 11 participants also anticipated additional steps after opting in, as they were unable to locate or understand how to specifically share records with CVS.

Additionally, 10 of 11 participants either misunderstood the scope of shared medical information or expressed concern about excessive information being shared with providers. These participants preferred the option to personally select shared records or have their provider refine the information being shared.

While navigating the Manage Your Medical Records Settings page, 4 of 11 participants mistakenly attempted to access the Manage Your Notification Settings section by clicking the link titled “Go to your profile on the My HealtheVet website.” They expected to find additional sharing settings or recipient selection options within this link.

Overall, 7 of 11 participants ranked the experience of understanding Pat’s Medical Records Settings as “difficult” or “very difficult” after completing the tasks in this section.

_"This screen right now is telling me what I’m sharing. I still don’t know that it’s actually told me who I’m sharing it with.”_ - Participant 09 (JAWS)

_“From what I see so far it gives them all your information… I don’t think a non-VA provider would need to know that I have PTSD… That sort of stuff is most definitely going to be privileged because it’s irrelevant to me getting my chronic back issue evaluated and fixed.”_ \- Participant 04 (Mag)

_“At this point I would say everything \[is being shared\], but that’s probably not the case. I would probably have to select which medical records I wish to share.”_ - Participant 07 (VoiceOver)

Labels: Accessibility, RESRCH: Usability Testing, PRDT: Medical-records, SFTW: Screenreader

**Finding 2: About half of the participants identified microbiology and pathology results, but almost all participants easily located imaging results.**

5 of 11 participants identified the Microbiology record when looking for Pat’s E. coli results. However, all 11 participants expressed a lack of confidence in their answer and 7 of the 11 participants considered checking the CBC for the results. None of the participants were familiar with the term “microbiology.”

Similarly, when searching for mole biopsy results, 6 of 11 participants selected the Surgical Pathology record, but most did so using a process of elimination. Five participants initially assumed the results were in the Microbiology record and many participants expressed disappointment that the term “biopsy” was absent from record titles. Similarly to the microbiology task, none of the participants were immediately familiar with the term “surgical pathology.”

On the other hand, 10 of 11 participants were able to find an X-ray result for Pat’s ankle injury without moderator assistance. The one participant who failed to find the imaging result did not check both pages of records, but this was unrelated to their use of assistive technology. Once participants found the actual X-ray image in the record, 6 of 11 expressed that access to the image was useful and beneficial for them, whereas 5 participants saw no added benefit. There was no correlation between AT type or device and task success rate or time-on-task.

Average time-on-task:

- Microbiology Results: 65 seconds
- Surgical Pathology Results: 59 seconds
- X-Ray Results: 20 seconds

_"To be honest with you, I don’t know \[why I chose Microbiology\]. I just said, okay, let’s see. This could either by microbiology or... there’s two of them it could have been... I can’t remember my medical terms.”_ \- Participant 01 (VoiceOver)

_“Microbiology. That’s typically what a biopsy was. To check for any problems or abnormal cells or infections.”_ - Participant 15 (JAWS)

Labels: Accessibility, RESRCH: Usability Testing, PRDT: Medical-records, SFTW: Screenreader

**Finding 3: All participants easily identified the test user’s most recent blood pressure, and most participants found a blood pressure result from several years ago.**

11 of 11 participants found test user, Pat’s, most recent blood pressure result when prompted. Screen reader users most often missed the blood pressure measurement on the Vitals landing page and instead clicked into “Review your blood pressure over time” to find the most recent result. These participants were frequently navigating quickly without listening to the entire screen reader dictation, which led them to miss some content.

Average time to find the most recent blood pressure result:

- Screen reader users: 22 seconds
- Magnification users: 6 seconds
- Voice command user: 3 seconds

10 of 11 participants also easily located Pat’s blood pressure reading from December of 2022. Participants had to navigate past many results to locate this result, likely contributing to the longer time-on-task measurements for magnification and voice command users. Two of six screen reader-dependent participants used the “JAWS Find” feature to locate this result, which allowed them to skip to the exact result they wanted without having to navigate through the rest of the page.

Average time to find the Pat's blood pressure result from December of 2022:

- Screen reader users: 22 seconds
- Magnification users: 63 seconds
- Voice command user: 48 seconds

Labels: Accessibility, RESRCH: Usability Testing, PRDT: Medical-records, SFTW: Screenreader

**Finding 4: All participants easily identified two notes when given only the note titles.**

11 of 11 participants successfully located a note called “Primary Care Note” when prompted with the note title. However, there was a difference in time-on-task among the different types of assistive technology. The voice command user was able to complete the task twice as quickly as the other AT-users because his lack of vision impairment enabled him to quickly identify the note visually. In contrast, the screen reader users were forced to navigate by line or header and magnification users were only able to see a portion of the page at a time, making the process of searching through notes more time-consuming.

Average time to find “Primary Care Note:”

- Screen reader users: 30 seconds
- Magnification users: 33 seconds
- Voice command user: 15 seconds

11 of 11 participants also located a note called “GI Consult Note” when prompted with only the note title. This note was on page 2 of Care Summaries and Notes, but pagination did not affect note findability whatsoever. 3 participants also mentioned that in real life, they typically use appointment dates as an anchor to find notes rather than the note titles. This finding provides more context to the task failure observed in previous studies in which participants were unable to identify notes on page two when only given a note timeframe and general topic. It appears that health literacy affected those participants’ ability to identify the requested notes due to the medical terminology in the note titles.

Average time to find “GI Consult Note:”

- Screen reader users: 39 seconds
- Magnification users: 36 seconds
- Voice command user: 51 seconds

Labels: Accessibility, RESRCH: Usability Testing, PRDT: Medical-records, SFTW: Screenreader

**Finding 5: All participants easily identified an allergy record.**

11 of 11 participants successfully found Pat’s oil allergy when starting from the Medical Records landing page. The average time-on-task was 53 seconds and there was no significant difference in timing among assistive technology types.

Labels: Accessibility, RESRCH: Usability Testing, PRDT: Medical-records, SFTW: Screenreader

**Finding 6: Few participants (3 of 11) independently found where to download the past three months of lab and test results from the Medical Records landing page.**

When asked to download lab and test results from the past three months, only 3 of 11 participants independently found the Download your Medical Records section on the Medical Records landing page.

The remaining 8 participants searched in Lab and Test Results but were unable to find somewhere to download records within a time range. Of those 8 participants who searched in Lab and Test Results, 5 assumed they would have to individually print each result within the past three months and the other 3 gave up when they were unable to find a place to select a time range of results.

8 of 10 participants who found the download page independently or with moderator help successfully downloaded the past three months of lab and test results for Pat without moderator interference. 9 of 10 participants stated that they would prefer to download their records in PDF format, including screen reader users.

After completion of the task, 4 participants requested more transparency in their records to guide them to the download page.

_“I'd say you threw me for a loop. I guess, when I was going through these earlier it had a place where you could print the current results, but I don't see it showing up on this page. I honestly don't know how I would do it.”_ \- Participant 03 (Dragon)

_"I thought it would have been smarter if it would have been near the labs and not having to go to a whole ‘nother section, and you could have just looked for what you needed near the lab and test results, and then, you know, modified it from there and just requested it to be done."_ \- Participant 13 (Mag)

_"It's almost the same \[as legacy BB\]... however, it just seems like there's more steps utilizing it this way... it just seems like so many steps."_ \- Participant 05 (Mag)

Labels: Accessibility, RESRCH: Usability Testing, PRDT: Medical-records, SFTW: Screenreader

**Finding 7: Most participants on average rated the Medical Records Settings and Lab and Test Results tasks as “neither difficult nor easy,” but rated the Vitals, Care Summaries and Notes, Allergies, and Download your Medical Records Reports tasks as “easy” or “very easy.”**

While most participants struggled with Medical Records Settings, magnification and voice command users struggled the most. On average, those 5 users rated the task as “difficult,” while the 6 screen readers on average rated the task as “neither difficult nor easy.” This higher rating is likely due to the fact that screen reader users must listen to each element of the page and are therefore less likely to miss important details.

_“To be honest, I have no idea \[how Pat’s records are being shared\].”_ - Participant 03 (Voice Command)

In Lab and Test Results, participants on average rated the task as “neither difficult nor easy.” There were no significant patterns that emerged among assistive technology types as lack of health literacy greatly affected participants’ task ratings rather than the site’s ease of use.

_“I hate it... it’s so complicated.”_ - Participant 05 (Mag)

In Vitals, Care Summaries and Notes, Allergies, and Download your Medical Records Reports, participants on average rated the tasks as “easy” or “very easy.” Given that most participants struggled to find the Download your Medical Records Reports page, the “easy” rating is likely correlated with the experience of downloading the records rather than finding the page to do so.

_"I think the accessibility is a lot more than what I really thought would be available. I mean, you can... and this is something that I tried to do in My HealtheVet before, and it's been a bit of a nightmare."_ - Participant 04 (Mag)

Labels: Accessibility, RESRCH: Usability Testing, PRDT: Medical-records, SFTW: Screenreader

**Finding 8: Dropdown options are not announced by screen readers when navigated using only the cursor.**

For the two screen reader users who utilize cursor rather than keyboard navigation, Medical Records performed as intended aside from one observed behavior. When the users clicked the date range “Select” dropdown within Download your medical records reports, the different options did not read out upon hover. It is possible that JavaScript is not set up to allow hover interactions, and that is why the participants experienced this issue.

## Additional Insights

**Additional Finding 1: Participants requested features such as sort, filter, and data visualization in Vitals and Care Summaries and Notes.**

In Vitals, 1 participant requested the ability to switch the sort order and 2 participants expressed the potential benefits of filtering by date. Two screen reader participants used the “JAWS Find” feature to search for a specific result. 3 participants also mentioned that “Review your blood pressure over time” seemed like it would lead to a graph of results. This finding has been reported in almost all past Medical Records studies, as well.

\*Please note that while data visualization only came up in Vitals, it has been requested in the past for Lab and Test as well. It was likely not requested during this study because the only test results participants viewed were written reports rather than numerical lab results within a range.

_“It said review over time. So I’m thinking it’s gonna give me some kind of written graph.”_ - Participant 01 (VoiceOver)

In Care Summaries and Notes, 4 participants requested sort or filter functionality to search by date or note type. Two screen reader participants used their own search functionality with “JAWS Find” to search parts of the note titles.

_“I’ve got to do this through, I don’t know how many notes. Because everybody puts a note in... I gotta go sit here and go through every one unless you know your sh\*t... It would be great to have this where I could sort it."_ - Participant 01 (VoiceOver)

**Additional Finding 2: Participants had mixed opinions on additional screen reader dictation.**

During the Vitals task, screen reader users were asked interview questions about their preferences regarding screen reader dictation for the total number of results within a domain.

Of the 3 users who were asked whether they would like to know the total number of blood pressure entries before clicking into “Review your blood pressure over time,” 1 participant said it would be nice to know, and two participants said it would not be necessary.

When all 6 screen reader users were asked if it would be helpful to hear “record _ of \_” while navigating through each blood pressure result, 2 participants felt negatively, 3 participants felt neutral, and 1 participant said it would be helpful.”

**Additional Finding 3: Participants would like more clarity on abbreviations and medical terms.** 

When faced with unknown medical terms, participants said they would turn to outside sources to look up definitions. 4 of 9 participants said they would use Google to look up unknown terms, and 1 of 9 participants said they use Perplexity AI for medical questions. 

4 of 9 participants also stated they would message their provider about unknown terminology or confusing results in their records.  

## Recommendations

_Put together initial recommendations here based on your findings along with supporting evidence. Review with your team, then edit as needed._

- Screen reader dictation for the “Continue” button should say “Continue to step _ of \_” on the Download your Medical Records pages.
- _One SR user mentioned that this would help them understand where they were in the multi-page process of downloading their records. This participant had trouble understanding the steps given the “Back” button listed before the “Continue” button and mentioned the potential benefits of additional SR dictation details._

## Further research needed

_Conduct quantitative research on MR metrics after launch: Anne Costello Kennedy_

_Conduct a contextual inquiry study on MR users after launch: Anne Costello Kennedy and Melissa Stern_

## Appendix

[Research plan](https://github.com/department-of-veterans-affairs/va.gov-team/blob/050d2a690f84961e8271557cf5c6bb06b1859938/products/health-care/digital-health-modernization/mhv-to-va.gov/medical-records/research/2025-01-usability-testing-rd4-at/research-plan.md)

[Conversation guide](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/health-care/digital-health-modernization/mhv-to-va.gov/medical-records/research/2025-01-usability-testing-rd4-at/conversation-guide.md)

## Who we talked to

**Recruitment criteria**

_We recruited 16 Veterans: 8 screen reader-dependent Veterans, 5 magnification-dependent Veterans, and 3 Dragon Voice Command-dependent Veterans._

We talked to **11 participants: 6 screen reader-dependent Veterans, 4 magnification-dependent Veterans, and 1 Dragon Voice Command-dependent Veteran.**

Audience segment:

- Veterans: 11
- Caregivers: 0
- Family members of a Veteran: 0

Gender:

- Male: 9
- Female: 2

LGBTQ+:

- Transgender: 0
- Nonbinary, gender fluid, gender queer, Two-Spirit (Indigenous only), or another gender beyond man or woman: 0
- Gay, lesbian, or bisexual: 0

Devices used during study:

- Desktop: 8
- Tablet: 0
- Smart phone: 3
- Assistive Technology: 11

Age:

- 25-34: 0
- 35-44: 1
- 45-54: 2
- 55-64: 4
- 65+: 4
- Unknown: 0

Education:

- High school degree or equivalent: 0
- Some college (no degree): 1
- Associate's degree, trade certificate or vocational training: 3
- Bachelor's degree: 1
- Master's degree: 5
- Doctorate degree: 1
- Unknown: 0

Race:

- White: 10
- Black: 0
- Hispanic: 0
- Biracial:
- Asian: 0
- Native: 0
- Unknown: 1
