# Medical Records in VA.gov Usability Study Round 3 (AT) Research Findings

August – September 2024

Anne Costello Kennedy ([anne.costello@va.gov](mailto:anne.costello@va.gov)) and Mel Stern ([melissa.stern@va.gov](mailto:melissa.stern@va.gov))

[Research readout](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/health-care/digital-health-modernization/mhv-to-va.gov/medical-records/research/2024-08-usability-testing-rd3-at/findings-readout.pdf)

**Jump to:**

[Hypotheses and conclusions](#hypotheses-and-conclusions)

[Key findings](#key-findings)

[Recommendations](#recommendations)

[Who we talked to](#who-we-talked-to)

[Further research needed](#further-research-needed)


## Research Goals

1. Identify any usability issues Veterans may experience in accessing their Care Summaries and Notes, Lab and Test Results, and Health Conditions.  
2. Understand Veterans’ sensemaking of medical terminology in Medical Records.
3. Understand Veterans’ needs and expectations within Medical Records.

## Research Questions

1. Can Veterans find the information they need to manage their healthcare related to:
    - Care Summaries and Notes
    - Lab and Test Results
    - Health Conditions
2. How do Veterans make sense of the terminology in their medical records?
3. What goals are Veterans hoping to accomplish within Medical Records?
4. What are Veterans’ expectations and use cases for printing/downloading Medical Records?
5. What are Veterans’ perceptions of the new experience in which they view their records on screen?
6. How do the goals, expectations, and experiences with Medical Records for Veterans who use assistive technologies vary from those who do not?

## Methodology

We conducted moderated usability testing sessions in which we asked participants to navigate a live environment while we observed their behavior, and asked follow-up prompts as needed.

## Hypotheses and Conclusions

_Hypothesis 1:_ Most Veterans will be able to access and understand the information about their medical records to manage their health.

MOSTLY TRUE: Most participants successfully located and understood most of the records if the titles included familiar terms.

_Hypothesis 2:_ Most Veterans will struggle to understand some of the terminology information within their medical records.

TRUE: Most participants struggled to understand “Lipid Panel,” and the acronyms in the Complete Blood Count (CBC).

_Hypothesis 3:_ Most Veterans will rate the new experience as “easy” or “very easy.”

TRUE: Most participants rated their experience with each domain as “easy” or “very easy” at the end of each task.

## Key Findings

1. Most participants (12 of 15) were able to find Health Conditions.
2. Most participants (8 of 15) successfully located the informational paragraph about time expectations for new health conditions to appear.
    1. 6 of 8 participants who use assistive technology found the content, while only 2 of 7 participants who do not use assistive technology found the content.
3. Most participants (14 of 16) were able to find Care Summaries and Notes and the Discharge Summaries.
4. Most participants (12 of 16) failed to find the Primary Care Nursing Triage Note without assistance.
    1. 9 of the 12 who failed did not notice pagination to take them to the correct page.
5. All participants (14 of 14) were able to locate Lab and Test Results without assistance.
6. Few participants (4 of 13) found the Lipid Panel while looking for a cholesterol test result.
7. Most participants (10 of 17) successfully located COVID test results. However, many participants expressed a lack of confidence in understanding the test name.
8. Use of medical jargon can be a barrier to Veterans finding and understanding information.
9. Participants would like more clarity on abbreviations and medical terms.
10. Veterans’ primary goal in Medical Records is to review changes to their record after an event.
11. Veterans often download their records to have on file or print their records to bring to appointments.
12. Most participants (8 of 10) provided positive feedback about the new My Health_e_Vet experience.
13. The differences in task success between participants who use AT and those who do not are nominal except for one task in which AT-dependent participants outperformed the non-AT-dependent participants.
14. Most AT-dependent participants (7 of 11) reported that they do not regularly use My HealtheVet to access their health records.
15. Screen readers detected and read content that is intended for print only while on list view pages for Care Summaries and Notes, Lab and Test Results, and Health Conditions.

## Details of Findings

### **Finding 1: Most participants were able to find Health Conditions.**

12 of 15 participants found the Health Conditions page when starting from the Medical Records landing page. The remaining participants who failed the task attempted to find information regarding the test user’s past conditions in Lab and Test Results and Care Summaries and Notes, stating that they would expect to find a history of their conditions within those pages.

_"When I scrolled down it said health conditions and I think you can't get more obvious than that." -_ Participant AT05 (Mag user)

_“It’s care at the VA, at least it’s a care summary. So, if I just wanted a list of what they do, that’s what a summary would be.”_ \- Participant AT01 (JAWS user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 2: Most participants successfully located the informational paragraph about time expectations for new health conditions to appear.**

8 of 15 participants referenced the informational paragraph in Health Conditions which states that results are available 36 hours after the provider enters them.\*

8 participants overall, 4 of whom found the notice, added comments based on their personal experience. 3 participants mentioned that they would expect updates to their record to show by the end of the day, while the other 5 participants expressed that they would expect their record to take 2-5 days to update.

_"I think we need to wait three days. I believe I’ve read that somewhere before on the My HealtheVet screen as it pertains to lab results.”_ \- Participant 08 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

\*See Finding 13 for more results broken down by AT usage.

### **Finding 3: Most participants were able to find Care Summaries and Notes and the Discharge Summaries.**

14 of 16 participants located the Care Summaries and Notes page when asked to review the provider notes from the test user’s doctor visits.

4 of the 9 successful AT-dependent participants took more than a minute to find Care Summaries and Notes as compared to both AT and non-AT users, who on average found the page within 26 seconds. This can likely be attributed to the complexity of navigating with their assistive technology and device, along with the participants’ health literacy.

15 of 16 participants were able to find Discharge Summaries when asked to count how many times the test user had been admitted to the hospital. However, all participants identified a Discharge Summary as related to a hospital visit. The average time on task for participants who do not use assistive technology was 26 seconds, compared to 64 seconds for those dependent on assistive technology. Magnification users took more than two times longer than non-AT users, and screen reader users took more than three times longer than non-AT users as they had to navigate through every note before locating the Discharge Summaries.

_"The provider notes here... you said provider notes, so it just says care summaries and notes.”_ \- Participant 01 (Cognitive Disability)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 4: Most participants failed to find the Primary Care Nursing Triage Note without assistance.**

12 of 16 participants failed to find the Primary Care Nursing Triage Note on page two of Care Summaries and Notes without assistance from the moderator.

9 of the 12 who failed did not notice the pagination necessary to take them to page 2 where the note was located. The 3 participants who failed but found the pagination assumed that the primary care secure messaging note was associated with a primary care visit, or did not identify any of the notes as a primary care visit and gave up. 4 participants who failed chose a Consult GI note, which happened to be the first note on the list sorted from newest to oldest. This statistic could have been influenced by the wording of the question, which specifically asked for the last time the test user saw their general physician. 2 participants gave up without guessing.

6 of 6 participants not dependent on assistive technology failed to find the note. The participants all self-identified as having a cognitive disability. 6 of 10 assistive technology users failed.

When asked to rate the ease of finding information within Care Summaries and Notes, 3 of 17 participants deducted points because they wanted to be able to group and filter their notes by provider. 2 additional participants deducted points because they wanted to filter by type of note.

_“February 28<sup>th</sup>, 2024, was a consult. That would be the last time Pat saw anybody, I think, in the hospital... so I don’t know if that’s the family type doctor or somebody else.”_ - Participant 07 (Cognitive Disability)

_"There’s a couple of secure messages, a nursing triage note... but within the two pages that are shown here, I don’t see it unless it’s part of the nursing triage note.”_ - Participant 08 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 5: All participants were able to locate Lab and Test Results without assistance.**

14 of 14 participants were able to locate the Lab and Test page starting from the Medical Records landing page. The average time to complete the task was 18 seconds.

Labels: RESRCH: Usability Testing, PRDT: Medical-records

### **Finding 6: Few participants found the Lipid Panel while looking for a cholesterol test result.**

4 of 13 participants looked in the test user’s lipid panel results when searching for a cholesterol test.

Of the 9 participants who failed the task, 5 found the pagination but still did not identify the lipid panel. 3 of the 9 participants thought cholesterol results could be found in a CBC (Complete Blood Count) test. Another 3 of the 9 participants thought cholesterol results could be found in a metabolic panel. Upon further research, it became apparent that complete metabolic panels include cholesterol tests, which may indicate why this trend occurred. Lastly, 2 of the 9 who failed knew that lipids included cholesterol, but still selected a different test result.

These findings suggest that the terminology used to display cholesterol test results may be inaccessible to Veterans who expect the result to be labeled more clearly.

_"If there was some reference to the word ‘cholesterol’… it would be a real quick indication to me that I didn’t have to go beyond that in terms of looking.” –_ Participant AT08 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 7: Most participants successfully located COVID test results. However, many participants expressed a lack of confidence in understanding the test name.**

10 of 17 participants successfully located COVID test results when prompted to find and share the test results. 6 of the participants who failed searched within Lab and Test results but did not identify the tests named “SARS-CoV-2 rna ql naa+probe~pcr” and “SARS-CoV-2 ag ql IA rapid~dss acc” as COVID tests. The remaining participant who failed was not able to see Lab and Test Results in their navigation due to their use of magnification on a mobile device.

5 of 17 participants associated the word “SARS” with COVID, while 4 participants did not. 2 participants recognized “CoV” in the test name and took a guess.

8 of 17 participants successfully identified the difference between the two tests as rapid versus PCR. 6 participants noticed that the names of the tests were different but could not attribute any meaning to their difference.

_“I don’t know if this means COVID. You know, it says COV, but I’m not quite sure that’s the terminology for COVID.”_ - Participant 01 (Cognitive Disability)

_“When I look at this paragraph, I am super confused. Nobody would understand what the heck this means... obviously there is a rapid test, but all these abbreviations, they don’t mean anything to me when I look at them... Okay, probe... it’s one of those nasal swabs that they did. The rest of this is just gibberish.”_ \- Participant AT04 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 8: Use of medical jargon can be a barrier to Veterans finding and understanding information.**

16 of 16 participants understood that hypertension meant high blood pressure when asked, and 15 of 16 participants associated “Discharge Summary” with a hospital stay. 4 of 7 participants successfully correlated anemia with one’s iron level, while the participants who failed expressed a lack of confidence in identifying the correct medical terminology.

_“I don’t see no clarifications on iron level. I don’t know too much about iron level. I’m not really medically inclined like that.”_ \- Participant 01 (Cognitive Disability)

16 of 16 participants did not instinctively understand the meaning of “HT” within “HT Monthly Monitor Note.” 11 participants found the meaning within the content of the note (Home Telehealth), and 4 participants incorrectly concluded that “HT” stood for hypertension, a condition which was discussed earlier in the session.

As stated in Finding 7, when searching for COVID tests, 4 of 17 participants did not associate the term “SARS” with COVID, 2 participants guessed on the COVID test after recognizing “CoV” in the test name, and 1 participant took an “educated guess.”

_"I struggle a little bit with terminology and some medical language that having terms either explained better, or some more information on the title of some of the information would be a tremendous help to me."_ \- Participant AT08 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 9: Participants would like more clarity on abbreviations and medical terms.**

10 of 15 participants requested definitions of acronyms and test names when reviewing the results of a CBC (Complete Blood Count). Participants also expressed a desire across the study to avoid abbreviations upon first mention of a medical term.

10 of 16 participants expressed that they would like medical term definitions within detail pages. 2 participants assumed a more detailed explanation of the health condition would be in the “About this code” dropdown and were unsatisfied with the information provided since the informational dropdown only addresses the alphanumeric codes included in some health conditions.

When faced with unknown medical terms, 11 of 16 participants said they would turn to outside sources to look up definitions. Participants most often mentioned Google as their search engine.

An additional 7 participants shared that they would ask their provider for help explaining some of the terminology seen throughout the study.

_"I would expect to have a definition of what \[the acronym\] is.”_ \- Participant AT02 (Mag user)

_“What would I do if I found something that was unfamiliar? I would follow up with a secure message to the provider.”_ - Participant 08 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 10: Veterans’ primary goal in Medical Records is to review changes to their record after an event.**

Every participant stated that they check Medical Records to look for imaging or lab results, review notes from their providers, or check past records for their own personal understanding.

Participants stated various methods for reviewing their own lab results: some participants only look at lab comments from their doctor, some compare their results to the reference ranges, and a few only look at tests that are familiar to them, expecting their doctor to reach out if any of the unfamiliar tests have results that cause concern.

When asked what information they would most like to see in a Primary Care Note, participants most frequently referenced the chief complaint, appointment summary, progress or plan of care status, and vitals.

When asked what information they would most like to see in a Discharge Summary, participants most frequently referenced their admission and discharge date and time, reason for visit, treatment received, attending doctor, and discharge instructions.

Some participants also stated that they were unable to locate records that they deemed “outdated,” look at imaging results within Blue Button, or find a specific record they were looking for. One participant expressed that they do not review their medical records on My HealtheVet because it is too difficult to navigate using magnification.

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 11: Veterans often download their records to have on file or print their records to take to appointments.**

14 of 18 participants mentioned printing or downloading their medical records. 4 of the participants explained that they print or download just to have on file, and 6 of the participants explained that they print or download the record to bring to outside providers or submit online for program requirements. These findings align with the outcomes from generative research conducted in 2022.

6 participants mentioned that they had to wait a long time for their record to download, with estimated wait times ranging from 5 minutes to 2 hours. When asked whether they would prefer to wait or receive a notification when their file was ready, 4 out of 5 participants said they would prefer a notification, specifically in the form of a text message. The remaining participant opted to wait.

When asked about their experience with Blue Button, many participants explained that they have had issues with the feature. Participant AT01 explained, "I couldn't download \[Blue Button\] and get the older records. And I don't know if that was because I was doing it incorrectly or it didn’t have it." Other participants explained that they had issues viewing imaging results, understanding the organization of the file (with and without magnification), or getting feedback from their screen reader when the file generation was complete.

_"Well, my file was 59,000 pages... oh my god, it was, I’d say about two hours \[to download\].”_ - Participant AT02 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 12: Most participants (8 of 10) provided positive feedback about the new My HealtheVet experience.**

13 of 17 participants who provided overall feedback about the experience ranked it positively. Positive feedback focused on intuitive site structure, ease of finding information, and quicker navigation. 2 participants called out the improved accessibility of the new experience, and 4 participants appreciated the ability to view records directly rather than having to use Blue Button.

While rating the ease of finding information during individual tasks, 13 of 17 participants cited issues with understanding terminology as a contributing factor of their less-than-perfect rating.

_"What stuck out is the emphasis on wanting to make it as user friendly for the Veteran who has certain challenges such as eyesight" -_ Participant AT08 (Mag user)

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 13: The differences in task success between participants who use AT and those who do not are nominal except for one task in which AT-dependent participants outperformed the non-AT-dependent participants.**

Both cohorts of participants performed similarly in 7 of the 8 tasks that involved locating information. On the task in which participants were asked when to expect a new health condition to be available, those dependent on assistive technology outperformed those who are not. 6 of 8 AT-dependent participants found the content, “Health conditions are available 36 hours after your providers enter them” at the top of the page compared to 2 of 7 non-AT dependent participants.

This difference could be attributed to the nature of navigating a page with assistive technology. We observed all four screen reader-dependent participants carefully navigating line by line when reviewing a page for the first time. Even those who later navigated by headers started each page line by line until reaching the cards. Magnification users have only a fraction of the page in their viewport, so they are more likely to be more deliberate in reading all content to complete their task.

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 14: Most AT-dependent participants reported that they do not regularly use My HealtheVet to access their health records.**

7 of 11 participants who use assistive technology stated they do not use My HealtheVet to access their health records. 5 of those 7 cited their inability to locate the records they required using the Blue Button tool. 2 said that using the website to access their records is too difficult with their assistive technology with one participant noting that they need their daughter to help download Blue Button reports.

_“When I blow things up too much, it just takes me too long to get through it and \[it’s\] too frustrating.” – Participant AT04 (Mag user)_

_“When you press the button \[to download Blue Button\], it doesn’t really give you feedback of if it’s done.” – Participant AT11 (JAWS user)_

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

### **Finding 15: Screen readers detected and read content that is intended for print only while on list view pages for Care Summaries and Notes, Lab and Test Results, and Health Conditions.**

During a session with a JAWS user, we observed an unusual focus state appearing between the card title link and the date entered when the participant navigated line by line on the Health Conditions, Care Summaries and Notes, and Lab and Test Results list view pages. The screen reader was detecting and announcing the elements since the CSS visibility and display properties do not fully prevent screen reader detection of H3 elements.

The participant did not notice the issue as they are an experienced JAWS user who navigates quickly and didn’t catch the repeated content. They are profoundly blind and thus unable to see the focus box on the screen.

Labels: RESRCH: Usability Testing, PRDT: Medical-records, Accessibility, SFTW: Screenreader, SPG: Cognitive Consideration

## Additional Insights

### **Additional Finding 1: No participants looked for the FAQ dropdown for reporting changes to their medical record.**

0 of 8 participants looked for information on the My Health_e_Vet website regarding how to report incorrect information. However, 7 of 8 participants stated on their own that they would contact their provider to make the correction.

### **Additional Finding 2: Most participants would choose to keep Health Conditions sorted in the current state, from newest to oldest.**

12 of 14 participants opted to keep Health Conditions sorted from newest to oldest, and only 2 of 14 participants preferred the ability to sort alphabetically or from oldest to newest.

14 of 14 participants were able to recognize the sort order, whether it was from the content on the page, or using context clues.

### **Additional Finding 3: Participants requested enhanced ways to narrow down their results.**

4 participants requested a search feature, 3 participants mentioned filtering by type of note, test result, or provider, and 2 participants suggested subcategories or labels attached to results to help sort through their results.

### **Additional Finding 4: Most participants thought the location field in Lab and Test Results referenced the clinic at which the sample was collected.**

10 of 16 participants stated the location was where the sample was collected when asked to identify the location listed in the record. 3 of 16 believed the location represented the processing site, and the remaining 3 believed collection and processing occurred at the same location.

When asked about their preference for the Location field, 9 out of 16 participants said they would prefer to have their medical records show the collection site. 4 of 16 said they would prefer to see the processing location, and the remaining 3 placed no importance on the location.

### **Additional Finding 5: Most AT-dependent participants used the side navigation when completing their tasks.**

8 of 10 AT-dependent participants used the side navigation at least once during the session. Magnification users were most dependent on it, using it for an average of 3 of 4 tasks. This includes a participant on an iPhone who accessed the mobile menu. This usage is likely attributed to the condensed viewport that results from magnification over 400%.

5 of 7 non-AT-dependent participants navigated with the sidebar at least once during the session. The remaining 2 participants were using mobile devices.

_“I like the headings in the left under Medical Records.”_ \- Participant AT07 (Mag user)

## Recommendations

- Change the &lt;h3&gt; tag for the title links on all list view cards to a &lt;span&gt; element. Use aria hidden=”true” to explicitly hide it from assistive technologies.
  - _This will prevent screen readers from detecting content that could potentially cause confusion._

## Next Steps

_Socialize Research: Anne Costello Kennedy_

_Update Designs: Scott Tyrcha_

_Work with Sitewide Content on Content Updates: Lexi Wunder_

_Conduct Additional Research: Anne Costello Kennedy and Mel Stern_

## Further research needed

_Conduct a findability study within Medical Records._

_Conduct a discovery study with Veterans targeting health literacy and medical terminology._

## Appendix

[Research plan](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/health-care/digital-health-modernization/mhv-to-va.gov/medical-records/research/2024-08-usability-testing-rd3-at/research-plan.md>)

[Conversation guide](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/health-care/digital-health-modernization/mhv-to-va.gov/medical-records/research/2024-08-usability-testing-rd3-at/conversation-guide.md>)

[Mural](https://app.mural.co/t/departmentofveteransaffairs9999/m/departmentofveteransaffairs9999/1704908877087/dd4cf16f4c31538494fab469857759f64059a79e?sender=u8633abbc30765ec453730801>)

## Who we talked to

**Recruitment criteria**

_We recruited 26 Veterans: 10 non-AT-dependent with cognitive disabilities, 16 AT users_

_We talked to_ **_7 non-AT-dependent Veterans with cognitive disabilities, 11 AT-dependent Veterans_**

We talked to **18 participants.**

Audience segment:

- Veterans: 18
- Caregivers: 0
- Family members of a Veteran: 0

Gender:

- Male: 14
- Female: 4

LGBTQ+:

- Transgender: 0
- Nonbinary, gender fluid, gender queer, Two-Spirit (Indigenous only), or another gender beyond man or woman: 0
- Gay, lesbian, or bisexual: 0

Devices used during study:

- Desktop: 13
- Tablet: 2
- Smart phone: 3
- Assistive Technology: 10

Age:

- 25-34: 1
- 35-44: 1
- 45-54: 3
- 55-64: 6
- 65+: 7
- Unknown: 0

Education:

- High school degree or equivalent: 5
- Some college (no degree): 2
- Associate's degree, trade certificate or vocational training: 3
- Bachelor's degree: 5
- Master's degree: 3
- Doctorate degree: 0
- Unknown: 0

Geographic location:

- Urban: 13
- Rural: 4
- Unknown: 1

Race:

- White: 8
- Black: 3
- Hispanic: 2
- Biracial: 3
- Asian: 1
- Native: 1

Disability and Assistive Technology (AT):

- Cognitive: 8
- AT beginner: 1
- AT advanced user: 9
- Desktop screen reader: 3
- Mobile screen reader: 1
- Magnification/Zoom: 6
- [Speech Input Technology](https://www.w3.org/WAI/perspective-videos/voice/) like Siri/Dragon Naturally Speaking: 0
- Hearing aids: 0
- Sighted keyboard: 0
- Captions: 1
