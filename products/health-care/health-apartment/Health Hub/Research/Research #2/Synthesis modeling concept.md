For Mo Studios: MY synthesis process in user research

I learned synthesis through a lot of trial and error. Throughout my career, I’ve typically been both the UX Designer & Researcher. This document will help illustrate the Synthesis Process I typically use in my User Research projects. 

This is the outline of the process I am using for the Moderated Tree Tests Studies for VA.gov Health Care website that we are currently engaging in. I am using actual data & specific examples from the tests we have just conducted.

Critical elements of the user research synthesis process:
1. Note taking and recording the session
2. Transcription
3. Coding and tagging
4. Affinity diagrams
5. Patterns and trends
6. Writing actionable recommendations and insights


What are codes and tags?

Codes and tags are words that represent something we have found in our data. We use codes/tags to categorize our raw research data.

From the notes & transcripts we have just collected, I am using tags/codes to help turn users' statements, observations, or attitudes into categories. These tags/codes will later allow me to pick up on the patterns I needed to present our findings and maybe create some recommendations.

How did I choose my codes/tags for this project?


There are two ways to make codes:
1. Inductive method: With the inductive method, we don't create any codes until we have gone through some data. We then find the codes in our data.
2. Deductive method: We come up with codes before we synthesize our data.

Deductive Data Tagging Method
I typically employ a deductive method which is coming up with codes or tags before I synthesis the data.
I use global tags in a lot of my research synthesis. The global tags I will be using on this project are:

- Goal: What the person is trying to accomplish as an outcome.
- Need: Something a person needs to fulfill a goal.
- Motivation: Why the person is trying to achieve that goal.
- Task: Something a person does to achieve a goal.
- Pain point: A barrier or difficulty towards accomplishing a goal.
- Tools: A tool a person uses to try to accomplish a goal.

For example, In our current research we are researching the Moderated Tree Tests Studies for VA.gov Health Care website and so far I've heard statements such as:

"Wasn't hard, but wasn't easy, because we have vets who aren't good on computers."
Pain Point as it can adversely effect Vets in different age groups or computer savvy capabilities

"That wasn't much fun, that's way too much clicking."
Again a Pain Point, some frustration with the search process

"MYHealth is talking about ME, benefits I've used. I want shortcuts to MY dental & Refill prescriptions"
Goal, as this person states they want a place for ME in MYHealth & shortcuts perhaps.

In turn, If we as a UX Design & Research Team decided used the inductive tagging method and created tags after reviewing the data, we would use this same information to create relevant tags. For example, if this information above was repetitive, we could create tags like:
- Frustration with too many clicks
- Lack of computer skills
- Long-term goals, like MYHealth being just about ME and perhaps shortcuts to most used features.

We could use the inductive coding method by reviewing a few transcripts and seeing what similar ideas or thoughts people are having. As I did above, I then try to create a larger category for similar thoughts or statements.


Creating the Affinity Diagram

Affinity diagramming is the process of bringing together all of our data into groups. At this point we take the tags we created and put them to work. If we decide to use global tags, these could serve as our broad categories.

For example, we could bring all the goals participants had under a goals section. Let's look at what this could look like with our actual user testers comments.


Goals:

- "MYHealth is talking about ME, benefits I've used. 
- "I want it simple, I don't want to search  for it. I don't want to click 4 or 5 times."

So, we've identified all of these as goals and brought them under the goals category. But there are a few variations in these goals. Through affinity diagramming, we can cluster similar goals into smaller subgroups.

We do this because we want to get to more specific recommendations. If we break the data down into similar, smaller points, we can have more apparent action items.

Here's how we might break these goals down:

Flexibility:

- I want shortcuts to MY Dental & Refill prescriptions"
- Enroll in HC: "I don't know if there is another place to put it. You might want to have it higher up the tree, esp. if it's a first time user. Where I work we try to do this so we don't loose people. Esp. if this is my first introduction to the VA."
- "Once I'm eligible, then I can  just be focused on my H.C. Having Admin stuff separate from MyHealth."


Simplicity

- "I don't want to click 4 or 5 times."
- "I found it bc I  just saw it"
- "It seems wonky that CoPay & travel pay are together. One is where I'm paying the VA & the other is paying me. It's like reverse."
- "This one sort of threw me, if it said "Services VA Covers" It could be better, but it might be just me."

Ease of Use
- "I like MYHealth, everything I need to manage my health, a one stop shop, all in one place."
- "I rely on a good search box. HC has so many shades of grey which makes it difficult"
- "I'd like to see Message your Dr rather than Messages. Spelling it out more then necessary may be better for the technically challenged"


Now that we have some clusters, or patterns, of information that we can go away and think through these with our Design team. 


How do I know something is a pattern or trend?

Usually, I define patterns or trends by the sample size. I typically think of a trend if 1/3 (round up) of the total sample size said something similar.

So, for our 10 participants in each tree, if three or more said they wanted flexibility, simplicity, ease of use I would categorize that as a pattern. 

Now, this isn't an exact science, and there can be exceptions, so we don't need to use this as a hard-and-fast rule. For example, one-off insights can be compelling. As we advance in our process, we will better judge patterns and trends, but the 1/3 rule is a nice place to start.


How do we write actionable recommendations and insights?


First off let's just make clear that the number one skill a user researcher can possess is writing compelling insights. These insights typically get teams excited about building products people will love. They push colleagues out of comfort zones and bring a product to the next level. However, as time goes by, the word "insight" has become misused and overgeneralized.

What Insights Aren't

Insights are not observations, quantitative data trends, or what a customer wants.

A generic definition of a user research insight might be "an actionable recommendation, based on research, that a team can use to make better decisions."

Nothing wrong with that definition but we want insights that are user-centric instead of product-focused.

What Insights Are

A nugget of truth about human behavior that pushes us to challenge our preconceived notions about how people act or perceive the world. They reveal to us the underlying motivations behind behavior.

If written well, insights can go further than the small product-recommendation box, and challenge an organization's beliefs on what they should be building for users.


Analyze and Use of Our Tree Testing Results

‍

What We're Looking For

Our testing tool Optimal Workshop is giving us results in the form of the following numbers:
- The percentage of testers who successfully completed each task ("success rate")
- The percentage of testers who successfully completed each task without making wrong guesses first ("directness")
- The average time needed for each task ("time)
- Where most testers clicked first for each task ("first click")
- Where most people finished for each task, their final answer, correct or otherwise ("destination")


Defining Success

The success rate of a tree test will always be lower than the success rate for the finished website, assuming we make improvements based on your learnings from tree tests and other research. Additionally  a finished website offers contextual cues, drop-down menus, a search feature, and other such details that make navigation easier. The difference can be huge--a success rate in the sixties on a tree test can be comparable to a success rate in the nineties on a finished site.

We can also look at relative results--does this tree have higher success rates than the previous versions? Is one task consistently taking longer than other tasks that should be similar?


Making Use of Results

It is important to consider the relationship between the various numbers. For example, if the directness is low for a given task, that's a problem, even if the success rate is high; users who accomplish their goal only after a lot of false starts and backtracking are going to be frustrated, even angry. Likewise, if directness and success are both good, but time is very long, that means the users are getting confused by something.


Conclusion

Tree testing has the advantage of being easier to set up and run than most of the other tests, thanks to modern tree testing tools. To create a new test, you just edit a spreadsheet. Tree testing is no panacea, but no type of testing is. For best results, use tree tests in conjunction with other testing types, to get a full picture of the progress of your development process.
‍
