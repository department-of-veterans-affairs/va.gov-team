# Website Performance Monitoring

---
## Phase I: Moderated Testing

#### Plan: HCA Website Performance Testing 
### Planning:
- Desired date range or test duration: Feb 2020 - March 2020
- Desired number of users: 2 Users
- How you'll conduct the testing: Create a full team setup of performance metrics for HCA Team including performance budgets and setting up alerts in Slack
- How you'll give the test users access to the product in production w/o making it live on VA.gov: N/A

### Results:
- Number of users: 2 Users 
- Number of bugs identified / fixed: 5/5
- Was the data submitted (if any) easy for VA to process?: The data is stored in speedcurve right now, but we can export it to VA whenever we have a data storage option. Alerts are being sent to VA Slack and email summaries are going to the admin users.
- Types of errors logged: Dashboard Setup issues, Team user management setup
- Any UX changes necessary based on the logs, or feedback on user challenges, or VA challenges? N/A
- If yes, what: N/A

## Phase II: Unmoderated testing

#### Plan: Pilot Testing with Facilities Team
### Planning:
- Desired date range: 03/13/20 - 04/28/20
- Desired number of unique users: 2
- How you'll make the product available in production while limiting the # of users who can find/access it: N/A
- "Success" criteria (by the numbers):
  - Full set of checks run weekly for one url
  - Performance Budgets are set for every metric
  - Performance Budget alerts are successfully sent to Slack
  - Number of performance budget alerts sent
  - Weekly report of all metrics that exceed performance budgets 

### Results:
- Number of unique users: 2 Users
- Actual results
  - [x] Full set of checks run weekly for one url
  - [x] Performance Budgets are set for every metric
  - [x] Performance Budget alerts are successfully sent to Slack
  - [ ] Number of performance budget alerts sent
  - [ ] Weekly report of all metrics that exceed performance budgets 
- Was the data submitted (if any) easy for VA to process?: Alerts are being sent, Weekly email alert is being sent. Data is not being stored anywhere currently.
- Types of errors logged: Onboarding & Setup, Offboarding
- Any UX changes necessary based on the logs, or feedback on user challenges, or VA challenges? N/A
- If yes, what: N/A


## Go Live!

### Planning:
- Desired date: ?
- Post-launch KPI 1: VSP has setup 100% of VFS teams in Speedcurve
- Post-launch KPI 2: Number of metrics that exceed performance budgets
- Post-launch KPI 3: Performance gains per team per metric
- Post-launch KPI 4: Number of optimization opportunities identified and scoped

#### Create a full list of teams on VSP
- [ ] Identify team admins (product leads, dev leads, FE devs)
  
#### Create teams on speedcurve
- [ ] Add Admins to their teams
- [ ] Create performance budget dashboards
- [ ] Link perf budget alerts to Slack
  
#### Demo of Speedcurve Functionality
  - [ ] Schedule & Record Zoom Meeting Demo
  - [ ] Link to Zoom Recording in Help Documents

#### Speedcurve Documentation
  - [ ] 'VSP Setting up Speedcurve' Documentation
  - [ ] 'VFS Team Admin Options for Speedcurve' Documentation
  - [ ] 'Track, Test, Optimize Performance with Speedcurve'
 

- Go / No Go: (ready / not ready)[https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/platform/product-management/go-no-go-meeting-template.md]

### 1-week results:
- Number of unique users: x
- Post-launch KPI 1: VSP has setup 100% of VFS teams in Speedcurve
- Post-launch KPI 2: Number of metrics that exceed performance budgets
- Post-launch KPI 3: Performance gains per team per metric
- Post-launch KPI 4: Number of optimization opportunities identified and scoped
- Any issues with VA handling/processing?: yes/no, lorem ipsum
- Types of errors logged: lorem ipsum
- Any UX changes necessary based on the logs, or feedback on user challenges, or VA challenges? yes/no 
- If yes, what: lorem ipsum

### 1-month results:
- Number of unique users: x
- Post-launch KPI 1: VSP has setup 100% of VFS teams in Speedcurve
- Post-launch KPI 2: Number of metrics that exceed performance budgets
- Post-launch KPI 3: Performance gains per team per metric
- Post-launch KPI 4: Number of optimization opportunities identified and scoped
- Any issues with VA handling/processing?: yes/no, lorem ipsum
- Types of errors logged: lorem ipsum
- Any UX changes necessary based on the logs, or feedback on user challenges, or VA challenges? yes/no 
- If yes, what: lorem ipsum

## Post-launch Questions 

1. How do the KPIs you gathered compare to your pre-launch definition(s) of "success"?
1. What qualitative feedback have you gathered from users or other stakeholders, if any?
1. Which of the assumptions you listed in your product outline were/were not validated? 
1. How might your product evolve now or in the future based on these results?
