# Initial research roadmap

Ask VA VA.gov Team

Last updated by @tygindraux on June 27, 2023

## 1: Question protocol

Through meetings or structured interviews with different business lines using a WIP Sketch prototype, we can determine which fields are required in order for agents to deliver the service. This is often called a [question protocol](https://www.uxmatters.com/mt/archives/2010/06/the-question-protocol-how-to-make-sure-every-form-field-is-necessary.php). We should also review the [agent survey responses](https://drive.google.com/drive/folders/1fzvPNHl5RHBPesUOwRf-wFq_bK5QXcfy?usp=drive_link) to learn more about what is and is not working.

This should also involve meeting with the CRM team to determine routing rules and limitations and reviewing the [CRM team responses](https://docs.google.com/document/d/16kPSXAHtFiuZIaLrbc19t7wkctAy8ID1/edit) to our questions.

|Goal|Research questions|
|:--|:--|
|Understand which fields are necessary in order for agents to deliver the service|Who uses the answers to each question in this form?<br>What do they use the answers to each question for?<br>Which fields are required in order to answer a query?<br>If an answer is required, what happens if a user enters something random in order to get through the form?<br>Why are optional questions part of the form?<br>How does this process differ across use cases (or categories and topics), if at all?<br>What makes it take longer to offer a response to the user?|
|Understand which fields are necessary in order to route queries to the right place|Which fields does the routing require in order to send queries to the right people?<br>Are there fields that have a greater impact on routing to queues than others? In other words, that would break more queues?<br>Which fields can change without affecting routing?<br>Why are queries routed to the wrong place? Is it user error that is causing the misrouting, and if so, where does this happen most often in the form?|

## 2: Understanding form fields and dashboard study

Through moderated usability testing with users we should use high-fidelity Sketch prototype(s) to learn how they expect to answer questions, review a past or ongoing inquiry and get help if they encounter an issue.

|Goal|Research questions|
|:--|:--|
|Understand how users expect to answer questions and in which order|Do people understand what each question is asking them?<br>Do the form patterns match people’s expectations of how they would answer each question?<br>Are people missing information on any question, page or sequence of pages?<br>Are there too many or too few questions per page?<br>How many fields or prompts are too many?<br>Is the order in which questions are asked intuitive, or does it cause confusion?<br>Is it clear how information has been pre-populated?<br>Is it clear how much longer the form is?<br>Do people understand how to edit their answers on the review page?<br>How long do people expect it to take to ask a question?|
|Understand what users expect to see when they review a past or ongoing inquiry|What do people need to know about the status of an ongoing inquiry?<br>When do people decide to review inquiries? When they get an email notification? When they're logged into their account for another reason?<br>What do people need to know when they review a past or ongoing inquiry?<br>How do people find past inquiries? For example, do they use the sort feature?<br>What challenges do people encounter when reviewing the status of an ongoing inquiry?<br>How does this differ for different types of users? For example, those who have personal and business queries?<br>What do users expect to happen after they receive a reply to their ongoing inquiry?|
|Understand whether users know where to get help or what they will do if they encounter an issue|If someone encounters an issue or doesn't understand something, what do they do?<br>Do people expect to be able to give feedback about this form while or after they are using it? If so, how?|

## 3: Usability and wayfinding study

Through moderated usability testing with users we should use a coded, working prototype(s) to review whether they can find Ask VA around VA.gov, authenticate if necessary or desired, and successfully submit and review inquiries.

|Goal|Research questions|
|:--|:--|
|Review whether users can successfully submit and review an inquiry|Is the form equally usable on mobile and desktop?<br>Is the form accessible to people who have cognitive considerations?<br>Is the form accessible to people using assistive technology?<br>What challenges do people encounter when submitting an inquiry?<br>What challenges do people encounter when reviewing an ongoing or past inquiry?|
|Review where Ask VA should live and be linked to from|Where are people when they realize they might need to ask a question?<br>Which steps do they take when they have a question? As examples, do they use the search, go to contact us, or something else?<br>Where do people expect to go to find AVA?|
|Review how users experience authentication|Why do people choose to sign in or not?<br>Is it clear when sign in is and is not required?<br>Are people able to sign in if they need to?|

## 4: Future Ask VA comparative analysis

Through a comparative analysis of similar online “Contact us” experiences, we’ll examine how other organizations have approached answering user questions through embedded forms.

Chosen organizations will be relatively large with knowledge distributed across multiple teams, provide services to a customer or user base, and provide an option for authentication.

|Goal|Research questions|
|:--|:--|
|Understand how UI decisions affect the user experience|Which components are interactive?<br>Which components are static?<br>How do different UI components affect the user journey and experience?|
|Understand how  content/IA decisions affect the user experience|What options do users have to resolve issues or find answers on the website?<br>Does the website surface FAQ content to help users find answers before choosing a communication channel? After choosing a specific channel?<br>What other communication channels are included (live agent, chatbot, call/text, email, etc.)?<br>If there is a contact form, is it integrated into other communication channels? How?|
|Understand how the authenticated experience compares to the unauthenticated experience|Does the website encourage users toward an authenticated experience? If so, how?<br>What communication channels are limited to authentication, if any?<br>How do unauthenticated users track messages, if they can?|

## 5: Future Ask VA concept study

Through moderated concept testing with users we should use low-fi stimuli or Sketch prototype(s) to understand users' expectations for a future-state Ask VA. This will include how users expect to start an inquiry, categorize topics and subtopics and ultimately, what they expect to get from Ask VA in an ideal world.

This should also involve reviewing Chatbot or Ask VA data to learn what people ask about in their own words and the conversational approach to getting an answer.

|Goal|Research questions|
|:--|:--|
|Understand how users expect to start an inquiry|How do people expect to start an inquiry? As examples, by entering free text, selecting a topic, answering questions (like TurboTax), or another way?|
|Understand how users categorize topics and subtopics|Which topics do users contact us about (in their own words)?<br>How do they break topics into subtopics (in their own words)?|
|Understand which outcome(s) a user expects from AVA|Why are they using Ask VA for their inquiry instead of another method?<br>What does someone expect to receive from AVA? As examples, FAQs, a link to a page, specific information related to their query, help from a person or community, or another option.<br>When do people expect to get responses to their message?<br>If they expect to talk to someone, how soon after they start their inquiry?<br>How would this work in an ideal world?|
