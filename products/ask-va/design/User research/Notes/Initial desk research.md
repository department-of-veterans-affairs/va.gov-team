# Initial desk research of previous VA studies
Last updated by @tygindraux on June 9, 2023

## Jump to
[List of studies](/list-of-studies)
<br> [Details of studies](/details-of-studies)
<br> [Key takeaways](/key-takeaways)

## List of studies
1. [Profile Notification Settings, Add Email Channel - January 2023](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#1-profile-notification-settings-add-email-channel)
2. [Disabled Veteran Accessibility Feedback - 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#2-disabled-veteran-accessibility-feedback)
3. [MCT Chatbot as AVA Front Door - Dec 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#3-mct-chatbot-as-ava-front-door)
4. [MCT Virtual Agent Chatbot Login.Gov and ID.me Moderated Interviews - Dec 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#4-mct-virtual-agent-chatbot-logingov-and-idme-moderated-interviews)
5. [Profile Editing Evaluation - September 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#5-profile-editing-evaluation)
6. [Chatbot Feature Prioritization - August 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#6-chatbot-feature-prioritization)
7. [MCT Omnichannel Experience: Co-Design Phase II - June 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#7-mct-omnichannel-experience-co-design-phase-ii)
8. [VA Orchid, Virtual Agent Chatbot - June 14, 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#8-va-orchid-virtual-agent-chatbot)
9. [MCT VHA Virtual Agent Research - June 24, 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#9-mct-vha-virtual-agent-research)
10. [MCT Omnichannel Experience: Co-Design - March 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#10-mct-omnichannel-experience-co-design)
11. [Virtual Agent Authentication Usability Test - March 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#11-virtual-agent-authentication-usability-test)
12. [VSP, Ask VA - Business, Personal Tabs (IRIS) - January 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#12-vsp-ask-va---business-personal-tabs-iris)
13. [Needs of Spanish Speaking Veterans for the Virtual Agent - January 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#13-needs-of-spanish-speaking-veterans-for-the-virtual-agent)
14. [MCT Virtual Agent Facilities Conversational Design - January 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#14-mct-virtual-agent-facilities-conversational-design)
15. [Virtual Agent Automated Content and Claims Feature Usability Testing - Nov 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#15-virtual-agent-automated-content-and-claims-feature-usability-testing)
16. [VSP, Ask VA (IRIS) - July 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#16-vsp-ask-va-iris)
17. [Virtual Agent Inclusive Design interviews - June 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#17-virtual-agent-inclusive-design-interviews)
18. [VSP, Ask VA (IRIS) - April 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#18-vsp-ask-va-iris)
19. [VA.gov Relaunch - 2018](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/2023-06-Initial%20desk%20research.md#19-vagov-relaunch-involved-multiple-studies)

## Details of studies

### 1. Profile Notification Settings, Add Email Channel

`one thing per page` `forms`

|Issue|[#214](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/214)|
|:--|:--|
|Date|01-2023|
|Team|Profile, Authenticated Experience|
|Background|Currently, the existing notification preferences we support all happen to only use text message as their means for getting in touch with users. However, we know that we'll soon need to support notifications that use email as a channel, and maybe some that support both text message and email as options. We want to do some research around how we can incorporate this additional option into the notification preferences interface so that we're ready to move quickly once this becomes a need for both users and stakeholders.|
#### Objectives
* Determine usable and scalable approach for adding email as a channel.
* Determine usable and scalable approach for adding more notification preferences to the page.
* Determine what level of information people need in order for them to decide whether they want to edit/update their preferences.
#### Findings
* The auto-save edit pattern in current designs was unanimously preferred to the read/edit (edit on a separate page) alternative. Participants were easily able understand and interact with our current auto-save pattern, even with more notifications and channels than we have on the page today.
* People were able to work through these problems without significant guidance from the moderator, but still found the auto-save pattern to be easier and faster to navigate. This further supports the findings from our [profile editing evaluation study](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/identity-personalization/profile/Research/2022-09-profile-editing-evaluation/findings-summary.md) that a “one thing per page” approach is not ideal for the short forms in the VA.gov profile.
* No one was confused by the lack of a save button.
* People were not totally clear on what to expect from notifications we’ll be bringing over from My HealtheVet.
* 7 of 8 participants easily navigated the path to add their email address.
* The repetition of the prompt to add an email address wasn’t overwhelming for most people.
* Both variations of the design were equally usable on desktop and mobile.
* Some participants were not clear about where their notifications would be delivered.
#### Recommendations
* Use the pattern in the auto-save prototype for notification settings as we add channels and notification options.
* The prototype replaced the radio buttons we have today with checkboxes. This was easily understood by participants and allows us to cut the number of inputs in half, resulting in a cleaner user interface.
* Learn more about content of My HealtheVet notifications, and update content accordingly to set clear expectations about what they are.
* Reconsider how we are encouraging people to add their email address to their profile.
* Explore how we might make the input message pattern more accessible.
* Explore how we might surface meaningful and relevant links to people in the notification settings section.

---

### 2. Disabled Veteran Accessibility Feedback

`accessibility` `ask va` `feedback`

|Issue|Not available. [Link to findings document](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/teams/shared-support/accessibility/research/2022-feedback/a11y-feedback-research-findings.md).|
|:--|:--|
|Date|2022|
|Team|Josh Kim, A11y|
|Background|Our goal is to establish a process to collect a11y feedback from the public. In order to accomplish this goal, we need to (1) determine whether disabled Veterans are providing feedback through existing feedback mechanisms (and if not, why not?), and (2) start to gain preliminary insight or determine next steps on how to gain insights into disabled Veteran's behaviors, feelings, perspectives, and expectations on providing a11y feedback.|

#### Objectives
* How accessible (and to a degree usable) are current feedback methods on VA.gov?
* Where do disabled Veterans currently provide or expect to be able to provide a11y feedback on VA.gov (if at all)?
* What are all the current existing mechanisms (accessible or not)?
* What kind of a11y feedback do disabled Veterans provide (or want to provide) on VA.gov?
* Do some subgroups (or individuals) among disabled Veterans have a greater need (if at all) for providing and resolving accessibility feedback more than others?
* How is a11y feedback for VA.gov currently processed?
* What mental models do disabled Veterans have of the a11y feedback process on VA.gov?
#### Findings
* Contact Center surveys
  * The majority of the data we parsed through was noise, with little key signals that could answer or relate to our research questions
  * Out of 4000+ lines of potential keyword matches, we were only able to extract ~10-20 lines of potentially relevant feedback, but they were either too broad, were inspecific, or lacked context to extract any confidence from
  * This could be a symptom of the inaccessibility or discoverability of the feedback button and feedback survey for disabled Veterans, and may be a topic for future research
* Page analytics
  * Between January 1 and November 17, 2022, the accessibility link in the footer of modernized va.gov pages was clicked 26,005.
  * Of those clicks, 18,123 of them were triggered from a mobile device.
  * The 508 page received 56,290 page views, this means that about 46% of all traffic to the 508 accessibility page came through the footer link.
  * This data was analyzed at a very preliminary level; there is an opportunity to do a deeper analysis with a more longitudinal set of data.
  * We have determined that there is traffic from the footer to the 508 page – a follow up analysis should be done to determine why folks are going to the 508 page and if they are able to find what they are looking for there.
* Accessibility audits 
  * All of the methods of providing feedback to VA.gov that we audited have confirmed major accessibility issues which may prevent disabled people from submitting accessibility feedback.
  * 2 of the methods we audited have confirmed severe major accessibility issues which likely completely bars access to providing feedback.
  * Many of these methods were audited in the past based on Section 508 standards (as opposed to WCAG 2.1 AA) which does not cover responsive, mobile, and cognitive considerations).  Maintenance historically has not often been conducted post-audit, even with the introduction of updated standards.
  * They will likely not capture all potential accessibility or usability issues for disabled Veterans. We should consider the existence of issues as a sign that further testing and usability testing with disabled Veterans should be strongly considered.
  * WCAG 2.1+ (not 508) accessibility audits and usability testing with disabled Veterans using a variety of assistive technology should be conducted for methods we still don’t have access to (or are unaware of) including the IVR survey, facility QR codes, email, and more.
  * More research is needed to understand the disabled Veteran experience of calling My VA 411 as it is currently the only known usable method for disabled Veterans to provide accessibility feedback beyond the Section 508 email.
* Appended interview questions with Veterans
  * One participant did not know how to provide feedback, one would look for a "contact us" area, one would attempt to call the VA, and another would self-advocate through the Blinded Veterans Association (BVA)
  * Going to a physical location, like a VAMC, was a common fallback should preferred methods not work for 4 out of the 6 participants
  * Screen magnification users on desktop (2/2 in total) didn’t notice the VA.gov feedback button. This is likely due to screen magnification showing only part of the screen at any given time. As there’s no indication that the feedback exists on the bottom right side of the page, it may be missed by magnification users who scan the page left to right with a limited view. For example, consider the simulated image below.
  * Given these were appended onto interviews with different facilitators, the manner in which questions were posed were inconsistent. As such, the above insights should be interpreted as a strong call to do more research instead of a factual or permanent representation of all disabled Veterans.
  * This research only covered the needs of Veterans with low vision or blindness with zoomtext and screen readers; it does not address the needs of Veterans using other types of assistive technologies
* Contact Center Panel Interview
  * Ask.va.gov receives a11y tickets from folks communicating on behalf of someone else. It’s likely inaccessible as it doesn’t follow the VA design system and Aubrey’s team’s recommendations were unresolved due to platform limitations with the dynamic 365 portal. It was likely not tested for Section 508 compliance.
  * Medallia feedback button and intercept survey were tested last year, but screen reader users did not participate despite Ian making a request to Perigean. This may be easier this year with new partnerships with blinded Veteran organizations.
  * The primary call center is My VA 411 (800-698-2411). There’s also a White House national hotline. When a Veteran calls the number and reaches an operator, they’ve reached tier 1 support. If their issue cannot be resolved, it is escalated to tier 2 which is the contact center team. If it cannot be resolved there, it becomes tier 3 which is often for technical issues like editing the markup of the website.
    * We’re not sure how the TTY number is handled nor how accessibility issues are triaged.
    * Tier 1 agents can log calls in salesforce, but the interface is difficult to search. Many issues found within salesforce at a glance appear to be home related accessibility issues (as opposed to digital website issues).
    * There’s a possibility a11y feedback may stop at a tier 1 agent as the surface level problem may be addressed over call (reading out a data table) while still leaving the source of the issue unresolved (the data table itself is still inaccessible).
  * Medallia feedback has not yet been tested with disabled Veterans using assistive technology. Previous usability testing focused on (1) the initial feedback button and (2) an updated version of that feedback button which demonstrated significant usability improvements for able-bodied Veterans. Conducting research in the future with assistive tech users may unveil key usability insights related to more complex cases and lead to data-driven inclusive enhancements.
* Mike Manalo Interview
  * No interviews were conducted with disabled Veterans using assistive technology. This was due to Perigean wanting more specific guidance on what “assistive technology” meant. In this case, they got older Veterans using iPads (as opposed to technologies explicitly used for a disability like a screen reader or keyboard).
  * The more complex the issue, the more likely Veterans will call. There were forming patterns of older Veterans being associated with doctor appointments and facilities which could generally be resolved via tier 1 support, but any issue requiring more complex topics like verifying a GI Bill payment often went to tier 2 support. There’s an open question of what is effective communication: SMS? Phone? Etc?
  * Unsure if there are any particular groups using or not using 411. Salesforce may help answer that. The vast majority of issues are related to authentication. The contact center team is creating a service map of how tier 1 issues are escalated to tier 2, how long those issues sit, and how they are resolved.
* Section 508 office
  * VA.gov team to draft modernized accessibility statement. Team acknowledged that the Section 508 page was 15 years old and that a modernized accessibility statement in Veteran-facing plain language would be a welcome improvement in hopes of gathering more feedback through the Section 508 email address.
  * Veterans are frustrated they don’t hear back when they provide feedback. “Biggest complaint from peers is when they do complain they don’t ever hear anything. So someone needs to respond with details so they know they’re heard. Veterans feel like they complained but I never heard anything. So why should I mess with it.”
  * Managing who tickets go to and how they’re resolved is a complex process. When the Section 508 office receives feedback from Veterans through their email, they first determine if it is (or isn’t) an issue they can address. If they can address it, they create a servicenow ticket for their team. If they can’t, they find the appropriate team to forward it to. A pain point here is that when they forward tickets, there’s no guarantee the team it is forwarded to will provide a response back confirming a fix. Even if they do, it’s often too late for the Veteran who may have to sit on an unresolved issue for 6+ weeks.
  * Section 508 office is interested in the potential of ask.va.gov, but haven’t been included yet. The office is looking for a way to reduce the number of feedback ticketing systems and looking into ways to follow up on tickets with Veterans. Ask.va.gov may fill in that gap, but it’s inaccessible and the Section 508 office (to their knowledge) has not been included in auditing it.
  * It may be difficult to track data on usage of the Section 508 email. Currently, there are no analytics, and it may be a manual intensive process.
  * Veterans who prefer analog methods feel excluded. “I don’t use tech. Everything you do pushes guys like me further and further out. My wife is good with tech but she’s not a Veteran. Never seems to get anywhere. I don’t do it.” “What Pat said, someone on the phone. Neither AIRA or BeMyEyes is accessible through a regular phone. For me, logging into VA.gov, not a Veteran, they can’t get to the things Brad needs to get to.”
* Tim Hornik (BVA)
  * Some disabled Veterans are providing feedback, but Tim hypothesizes many more may be sitting with inaccessible products. Tim shared an anecdote of a social care worker who sent an email to the Section 508 office about the cerner patient portal. Without that social care worker’s relationship with the disabled Veteran and their intervention, the issue may have never been highlighted.
  * VEO historically has not considered the disabled Veteran experience, but is critical to collecting feedback. As an advocate, Tim requested VEO to have mechanisms and pathways for feedback both virtually and physically at VA centers in the past. This doesn’t appear to have been implemented. 411 may be too overwhelmed to help. Tim noted that 411 call center employees may not have the time, training, and space to record accessibility feedback and forward it to the appropriate places to be fixed.
  * The Section 508 page needs an update and more research. The page has existed for 15 years and includes content on both internal department information and Veteran facing services. It’s linked to from the footer on all VA.gov pages as “Accessibility” which may be misleading. Tim is worried that it won’t be discoverable as a footer item. He knows that people use it (including VA staffers) because we direct them to go there from this external site.
  * We should explore paths of least resistance for improving Medallia feedback. Tim noted it may be easier to just include a link that acts as an offramp to another form for accessibility feedback within the Medallia feedback options.
  * In past work with rehab centers, people didn’t deliver feedback. Tim noted that people would complain about accessibility issues in meetings, but wouldn’t formally report on it.
* Djilan Yao (VEO)
  * Uncertain if any VEO projects have specifically addressed accessibility or disabled Veterans. It doesn’t seem to be something the measurement team has investigated yet, but could be an area of interest. Evan and Dan may be the next people to talk to (if possible).
  * There are 4 main methods of sending out surveys. Most (if not all) are powered by Medallia. This includes (1) surveys on VA.gov (feedback button and intercept survey), (2) QR codes in facilities that link to surveys, (3) IVR surveys over phone which are then input into Medallia, and (4) surveys sent out to sampled individuals by email which link to surveys.
  * We know some of those surveys (on VA.gov) have accessibility issues documented in Tiffany’s audit. But we’re uncertain if those issues exist on other Medallia surveys too. For example, if other surveys aren’t within a modal, they likely won’t share the same major issues related to magnification.
  * The base survey template is 508 compliant (WCAG 2.0), but may not cover issues beyond that scope. Surveys are developed for 508 compliance and tested internally through the 508 office. If a survey taker is using a software or technology outside of the 508 boundaries, we are not able to ensure it will work properly.

---

### 3. MCT Chatbot as AVA Front Door

`chatbot` `ask va`

|Issue|[#193](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/193) and [#224](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/224)?|
|:--|:--|
|Date|2022-12|
|Team|VEO: VA Multi-channel Technology (MCT)|
|Background|This project will focus on researching and designing a conversational alternative to Ask VA (AVA) intake, which would allow users to submit tickets through a VA chatbot. Most participants didn’t have previous experience using AVA. Few participants have experience using a chatbot to submit a delayed-response secure message.|
#### Objectives
* Understand user expectations and comfortability with using a chatbot to perform AVA tasks, and how they would expect the new features to work.
* Determine pain points while submitting requests through AVA and discover how to mitigate them when submitting requests through the chatbot.
* Determine users’ comfort level in disclosing personal identifiable information (PII) within a chatbot conversation.
* Discover what kinds of tasks users would find most impactful or relevant to be able to accomplish through sending a secure message via chatbot.
* Understand user expectations around the intake and follow-up processes, as well as how they would expect to be informed and adopt the new feature.
#### Findings
* Users described chatbots being unhelpful due to a variety of reasons such as misinterpreting questions, unclear responses and inability to help with more complex tasks. Instead, some participants turn to secure messaging or reaching entities by phone in order to answer their questions.
* Participants mentioned using the chatbot for simple tasks and closed-ended questions, mostly recognizing a chatbot's language limitations.  Some mentioned analogous uses for a chatbot such as getting help from a phone provider or online shopping, but participants preferred access to a live agent in those instances, as well.
* The majority prioritize managing their health care through Secure Messaging while others mentioned seeking help for topics like education benefits, locating and filling out forms, and other VA services.
* Most participants view secure messages as an additional avenue to communicate with VA and value its ease of use, the ability to directly communicate complex issues with a human, and the ability to share relevant documentation instantly. Nevertheless, some participants found the response time to be inadequate and were frustrated when the responder was not knowledgeable enough to provide a solution.
* Participants generally felt that a chatbot could keep messages private, but most users felt reservations about chatbot security.
* Participants understood the advantages of logging in and would expect an authenticated query to yield more specific results. Although users understand that the chat would be limited to general inquiries if they decided to remain anonymous, 6 out of 9 participants favored an unauthenticated option. 
* Participants who had used AVA in the past mentioned they believed to be speaking directly with their provider when submitting a secure message, further underscoring their sense of security with the tool.
* Fewer participants felt comfortable inputting sensitive information into the chat setting than they do in a secure message.
* Most participants felt that basic information (contact information, subject, and issue description) is all that should be needed when submitting a ticket.  2 out of 9 participants felt VA should already have their basic information, expecting to only need to provide issue descriptions when submitting tickets.
* Participants agreed about the time it should take to receive a response in both channels; immediately in a chatbot and delayed via secure message. While most participants expect that submitting a ticket should take 5 minutes, they had split opinions on whether response times should vary based on issue topic.  Most figured that agent responses should be received back within 48 hours. Some thought all issues should be addressed with similar urgency while others felt that more complex issues could require more time.
> “If it’s a simple question, [I expect it to be] responded to on the spot. If it’s more complex, maybe it’s a couple hours later, maybe it’s the next day. So long as the information is conveyed to the person on the other side, then absolutely.”
* Most participants would expect immediate responses from a chatbot but would be willing to wait longer for a response from a live agent.
* Session participants expected to locate their historical and current tickets within a central space for easy access.  Participants wanted to be able to track the progress of their submitted tickets. Some participants also mentioned that they would expect to locate a ticket via a confirmation email or link. Some would expect to do so within chatbot.
* 4 out of 9 participants welcomed the ability to submit a ticket through a chatbot.
> “It will be kind of like having a normal conversation say like what can I help you with, submit my ticket then the chatbot starts to ask you your name, issue, whatever keywords that the chatbot can identify so then after everything and all the info that the chatbot needs, it says like this is a summary of what your ticket has, do you accept or do you decline. Then after it will say I'm sending a copy of this ticket to your email so you can have it.”
* Participants felt that if a chatbot were unable to answer their questions, the option to submit a ticket or connect with a human within the chatbot would be adequate alternatives.
* Some features participants appreciate in a chatbot are that it allows multitasking. In some cases, they also appreciate a chatbot’s ability to provide an adequate response without having to talk to a person.
* Most participants claimed they would trust the chatbot to route their requests to the right entities.
* Participants had varying opinions of how they would expect the process of submitting tickets to work and how to follow up with them. For example, following up on the ticket using chat or receiving an email.
> “If the agent knows that it might take three [or] four days, I would [expect] a message saying I’m working on it and maybe send an update like I haven’t forgotten about you and I’m working on it. That’s something you can show them on the ticket tab too on the title like the status, like a circle with a color green [or] orange.”
#### Recommendations
* VA associations help alleviate security concerns. Ensure the user knows who the message recipient will be. 
* Create an avenue for users to get meaningful answers while remaining anonymous. 
* Leverage the sense of security created by secure messaging applications and convey it within the chatbot conversation.
* Enhance a user’s sense of security by leveraging information available when authenticated and confirm chatbot security measures already in place.
* Leverage stored/available data when a user is authenticated and only request confirmation of data, data from unauthenticated users, or additional data relevant to a specific query.
* Users may find it reassuring to see the process status of a message. Avoid confusion and frustration by providing transparency into the process. It will be important to set expectations at the start that submitting a ticket through the chatbot will result in a delayed response from an agent.
* Users will likely also want to be able to track, be alerted of, and manage their submitted delayed-response tickets. Further probing is needed to assess user preferences for how they want to reply once an initial response is received from an AVA source.
* Further probing is needed to assess specific thoughts on the ticket submission journey in a conversational chat environment.
* Participants’ preference for interaction with agents indicates favorable views for adopting chatbot as AVA’s intake. Surface opinions suggest that a delayed-response option alleviates users’ hesitations about interacting with a chatbot. However, further probing is needed to assess finer points of a merged tool.
* Provide transparency into where the ticket will be routed, to proactively address concerns of the request not making it to the right person.

---

### 4. MCT Virtual Agent Chatbot Login.Gov and ID.me Moderated Interviews

`chatbot` `authentication`

|Issue|[#205](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/205)|
|:--|:--|
|Date|2022-12|
|Team|VEO: VA Multi-channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking login assistance for their new or existing Login.gov and ID.me accounts from the VA chatbot.|
#### Objectives
* Understand user expectations and desires around the information and interactions the VA chatbot can provide regarding login assistance for their new or existing Login.gov and ID.me accounts.
* Which keywords would a user expect to type in for help with a Login.gov or ID.me account?
* Are the help tasks what the user expects for an existing Login.gov or ID.me account?
* What additional tasks associated with Login.gov or ID.me account assistance should the chatbot be able to perform?
* How do users feel about the button layout and navigation between button stacks?
#### Findings
* Some participants initially struggled with getting the result they wanted based on the keywords they chose to type.
> "I asked a very straightforward question and it doesn't know what I'm talking about."
* Most participants had a reasonable idea of wha tinformation the 'I don't know' button would return and that it would likely provide more information on account types.
* Particiapnts thought that the language of the quote was too much, confusing and felt like you're 'talking to an algorithm.'
* Login.gov options (forgot my password, sending my ID, etc.) made sense and were expected. Some participants didn't know what 'sending my ID' meant.
* Participants stated that much of what the chatbot provided was something they might expect, and it was clear what they would do next.
* Participants shared that they liked the navigation of the "See more options" and "Back" buttons. They thought this was easy, helpful, and familiar to them.
> "Oh, that's amazing because I can always go back but if I need more options, I can view those and still go back. Other ones like Amazon force you to click the next one and then if you don't click the desired one it brings you back to a brand-new page...it's a waste of time. So, allowing me to go back is really nice."
* Most participants stated they didn’t mind leaving VA.gov to receive the answer they were looking for and get further information.
* Most also liked that a separate tab was opened so they could return to the VA site after. 
* Most participants were unclear about the "What you'll need" button and what information it might provide. They were more confused after clicking and receiving seemingly mismatched information.
* As previously reflected, users began getting frustrated after trying different variations of questions to ask only to receive unrelated information. 
> "I wish it would cluster words together... like when you type email, there should be more associations then that one that first popped up. I feel like the clustering association could be setup differently."
> "Typing in the something and nothing comes up you get a little discouraged. But then I said maybe I'm not asking the right questions... by the last scenario I put ID.me account and got everything I needed which made me feel good."
* Most participants welcomed the idea of leaving the chatbot to be provided with a help article that gave them more information than they expected.
> "I like how it would take you to a knowledge-based article that would give you a full explanation."
* Several participants mentioned a live-agent feature when asked if anything was lacking. Some participants said they preferred to interact with an actual human representative if they couldn't find the answer they were looking for.
> “I guess I'm used to more human interaction...talking with an actual person. If they didn't understand me they can ask me more questions and narrow down exactly what I'm looking for instead of just providing me a link that might not always answer my question."
#### Recommendations
* Pursue more word associations based on what the user might type.
* Ensure language is simple and concise.
* Consider updating 'Sending my ID' with a more straightforward name.
* Consider updating the "What you'll need" button with a clear alternate title and ensure the associated information matches. 

---

### 5. Profile Editing Evaluation

`one thing per page` `forms` `accessibility`

|Issue|[#181](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/181)|
|:--|:--|
|Date|2022-09|
|Team|VA.gov Profile, Authenticated Experience|
|Background|Accessibility specialists have been advocating for a “one thing per page” pattern for VA.gov forms for the last year. This pattern is known to improve the usability for complex forms by reducing cognitive load, improving error messages, reducing load times and more. We’re considering this pattern for profile, but we’re not sure if there are actual user problems this would solve since profile has relatively simple forms. This research will help us identify usability problems that would be solved by this approach.|
#### Objectives
* Learn whether or not our edit-in-place pattern presents major usability problems for people with cognitive disabilities on mobile devices.
* Identify any other usability hurdles in profile.
#### Findings
* 9 of 11 participants were able to update a VA.gov profile with in-line editing with relative ease.
* 5 of 11 participants experienced some minor confusion during the address validation process.
* In the contact information section, we observed some usability hurdles that slowed multiple people down.
* Participants were not bothered by encountering multiple alerts when updating contact information, though it took some longer than others to comprehend the information.
* 6 of 11 participants were disrupted by having to leave the notification settings page to add a mobile number.
* 5 participants missed the “Board of Veteran’s Affairs Hearing Reminder” notification name, which led to a misunderstanding about what the notification was for.
* 9 of 11 participants, including screenreader users, found in-line editing and a “one thing per page” approach to be equally usable.
 * No one commented on noticing they were going to a new page or staying on the same page without being prompted.
 * Once prompted, 8 participants stated they had not noticed they were going to a new page in the prototype, and shared their thoughts about the different approaches: 2 participants stated they preferred the one-thing-per-page approach of the prototype, 4 participants preferred to be on one page, and 5 had no preference.
 * Both participants who preferred the one-thing-per-page prototype said they preferred it because it felt simpler. This is likely due to the fact that the participants didn’t encounter any alerts like they did on VA.gov.
 * 3 participants shared concerns that loading a new page would negatively impact internet bandwidth.
 * 1 participant struggled to complete tasks that required multiple pages or disruptions: struggled to stay on task when having to go from one page to another, such as adding a mobile phone number while updating notification settings, struggled to recall to navigate from page to page, despite having already used the navigation menu in the setting, repeatedly triggered the same modal, seemingly unsure how to resolve the problem.
#### Recommendations
* For general editing functionality, continue using the single page editing pattern that is in place today.
* Improve the user experience for buttons in profile.
* Review analytics around our “currently editing another section” alert.
* Explore how we might simplify the address validation flow, and how to leverage analytics to see if quantitative data support what we observed in the study.
* Explore solutions to improve the user experience of managing notification settings when no contact information is on file.
* Improve the visibility of the notification name.
* Keep the extreme “short term memory loss” use case at the forefront for future design iterations.

---

### 6. Chatbot Feature Prioritization

`chatbot` `authentication`

|Issue|[#175](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/175)|
|:--|:--|
|Date|2022-08|
|Team|Virtual Agent|
|Background|The Chatbot is a self-service platform that can be accessed at any time by Veterans. The chatbot aims to provide value to Veterans by increasing awareness of existing VA self-service tools, decreasing the time Veterans spend waiting for an outcome, and allowing them 24/7 access to either anonymous or secure support. The chatbot was initially released in February 2022 so it is fairly new and unfamiliar to Veterans. Finally, the chatbot is currently situated as a subset of the VA Contact Us and can be accessed directly here.|
#### Objectives
* What features would users like to see prioritized based upon the following issues: the ability to provide users with sign in related information, problem escalation, password reset, and account creation?
* What are the primary pain points that exist around sign in related issues with users?
* How are users currently addressing and navigating these tasks?
#### Findings
Unable to access.

---

### 7. MCT Omnichannel Experience: Co-Design Phase II

`chatbot`

|Issue|[#127](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/127)|
|:--|:--|
|Date|2022-06|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking information from a VA.gov chatbot. User research will focus on the desirability of future state of Virtual Agent features to inform the longer-term roadmap.|
#### Objectives
* Understand user expectations for the level of information a virtual agent can provide regarding the disability rating and compensation, as well as the appeals process.
* Learn the desired interactions and depth of information the Virtual Agent needs to be able to provide.
#### Findings
* Users are likely to end the interaction with the chatbot after they have received the answers they were looking for and want a way to conclude the conversation.
* Some users disliked the guided experience with the buttons because they found it limiting and felt they were not in control of the conversation. Additionally, feelings of frustration arose when responses felt redundant and there was no way out.
* A few users preferred the simple, straight--forward experience of being provided a link to read information for themselves. Some of these users would only use a chatbot for high--level, basic level, basic questions, rather than information on their personal case.
* Most users appreciated being provided a link with additional information and resources and would click to read more.
* In some instances, users felt the link was a distraction and could lead to the user accidentally leaving the chat.
* Some users liked that the chatbot provided resources such as links to PDFs and forms and were likely to download them for future use.
* Some users felt overwhelmed or confused when being provided too many options or too much detail, leading them towards ending the conversation. Some also felt the segmented and concise response helps them fully digest the information and not miss any key details.
* Users generally liked the step-by-step guidance, which increased engagement because they believed it helped break down complex tasks into digestible pieces. This can be particularly helpful for newer users.
* Some users want the chatbot to provide information on their case––specific next steps, such as filing a claim or appealing online.
* Many users wanted or expected the chatbot to have the ability to provide personalized responses based on their unique situation. To ensure they receive this experience, most users will articulate their questions in complete sentences and provide case specific information. Some would not have a problem providing their personally identifiable information within the chatbot, while others would expect the bot to pull it from their account.
* Users appreciated the guided experience provided in the chatbot and prefer that over searching on VA.gov as it sifts through information for them. Conversely, searching on VA.gov is viewed as a futile and frustrating task.
* Some users would opt for outside sources rather than VA to find answers. Additionally, some would start with other channels instead of coming to the chatbot to find information.
* Users were satisfied with the experience when the chatbot provided comprehensive, digestible and intuitive responses. In many cases, a general idea or a non-overwhelming response was a satisfactory answer.
* Many users expressed a desire to speak with a live person instead of a chatbot. In some cases, they would like for a chatbot to have the ability to transfer directly to a live agent, others would skip the bot and start with a live person because they appreciate the active conversational aspect.
#### Recommendations
* Include options to "continue" or to "finish" conversation after each pathway to provide a clear way to navigate.
* Make it clear to users they can override the suggested button pathways by typing in their questions.
* When possible, provide links toward the end of a topic area and open the link in a separate tab.
* Ensure that only relevant information and options are provided to the user to not overwhelm or confuse them.
* Ensure responses are segmented and concise to help users fully digest the information and not miss any key details.
* As many perceive the task of calculating disability ratings as an already lengthy process, ensure all responses and steps provided are clear and concise. If possible, allow users the ability to input their own disability ratings to help contextualize how their determination was reached.
* Leverage user profiles and information [PII/PHI] provided through chat to ensure solutions are relevant and personalized to the user's unique needs.
* Include interactions such as tooltips, an option to save the chat for reference later, and animations to help users contextualize information.
* When available, give users the option to connect to a live agent in the beginning of the conversation and upon chatbot failure to provide adequate resolution.

---

### 8. VA Orchid, Virtual Agent Chatbot

`chatbot` `feedback`

|Issue|[#151](https://github.com/orgs/department-of-veterans-affairs/projects/880/views/1?filterQuery=chatbot&pane=issue&itemId=21794331)|
|:--|:--|
|Date|2022-07|
|Team|Virtual Agent|
|Background|Our research will attempt to gain insight on the reason for the lack of completion of the feedback survey. The research will also help us understand how users expect to be taken through a password reset flow. Finally, we have identified four areas to expand the chatbot into and this research will help us prioritize the features we focus on for users.|
#### Objectives
* Gain insight on lack of feedback survey completion
* Take users through a flow to reset their password and gain insight on the expected flow
* Gain in	sight on future chatbot feature prioritization with users
#### Findings
Unable to access.

---

### 9. MCT VHA Virtual Agent Research

`chatbot`

|Issue|[#148](https://github.com/orgs/department-of-veterans-affairs/projects/880/views/1?filterQuery=chatbot&pane=issue&itemId=21794312)|
|:--|:--|
|Date|2022-06|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans, caregivers, and family members seeking information from a VHA chatbot. User research will focus on the desirability and perceived usefulness of health and health care related content and information, which will inform future product roadmaps and even content creation.|
#### Objectives
* Understand user expectations for the type of information a chatbot can provide about VHA services, features, and other information Veterans might expect from a chatbot.
* Learn what the desired VHA interactions and features are that the chatbot needs to be able to perform.
#### Findings
* Users wanted the ability to order and refill prescriptions through a VA chatbot.
* Users had varied interest in having a chatbot provide medical and dental coverage and provide medical and dental coverage information.
* Most participants expressed a strong desire to manage their medical appointments using a VA manage their medical appointments using a VA chatbot. Many users reported difficulties managing their appointments through current managing their appointments through current VA platforms and methods.
* Several participants expressed desires for the VA chatbot to check into appointments and VA chatbot to check into appointments and communicate onsite delays.
* Most participants stated that seeking medical records, test results, and receiving notifications records, test results, and receiving notifications of results were top needs.
* Most users found the ability to request or change to a new provider highly desirable.
* Users expressed frustrations with the current process of requesting referrals and options for the process of requesting referrals and options for specialists or Community Care needs.
* Users expressed a desire for an additional avenue for communicating with providers.
* Due to the amount of information and segmentation of experience for different VA touchpoints, many users struggle to find information that suits their needs.
* Users dislike the experience of contacting VA as it is difficult reaching someone, specifically someone who can provide an adequate or timely solution.
* Some users want a chatbot to help locate VA facilities providing services that suit their unique care needs.
* Users liked chatbots that are intuitive and offer guiding features, saying that is what gains their trust. Nevertheless, some users said those attributes still may not be enough to overcome their preferences for live agent chats.
* A few users expressed interest in a chatbot having functions that can aid in claims, appeals, and other Veterans Benefits Administration related financial inquiries.

---

### 10. MCT Omnichannel Experience: Co-Design

`chatbot`

|Issue|[#96](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/96)|
|:--|:--|
|Date|2022-03|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking information from a VA.gov chatbot. User research will focus on the desirability of future state of Virtual Agent features to inform the roadmap for upcoming configuration.|
#### Objectives
* Understand how users will interact with a VA chatbot to retrieve VA facilities information.
* Understand the type of language Veterans used to communicate their needs. Are they able to understand the current VA language and terminology? 
* Validate the type of information users are searching for regarding specific VA facilities. 
* Learn what, if any information related to VA facilities that Veterans would like but are not currently available on VA.gov
#### Findings
* Many users expressed that they would search for information using VA.gov only when specific needs arise and not for browsing.
* Most users solely rely on private search engines for VA -related information as they offer the most direct and relevant results. This reliance on private search engines is often attributed to negative past experiences using the VA.gov search feature.
* Some users were confused by the term “Virtual Agent” and believed they would interact with a customer service representative or live agent.
* Users expressed frustration when chatbots provide generic or canned responses, leading some to avoid chatbots altogether, and opt to call a live agent or search for a resolution themselves.
* Users become frustrated when a chatbot is unable to recognize their inquiry and forces them to be stuck in a loop. Users expect the Virtual Agent to accurately route them towards a solution. If it fails to understand intent, it should present users with probing questions.
* Many users prefer the personalized touch of a human interaction, along with the efficacy a live agent provides. Users expect the ability to escalate within a reasonable timeframe during the same interaction.
* Users want personalized results tailored to their profile and unique situation when engaging with a Virtual Agent, including comprehensive guidance to navigate complex and opaque processes, like claims and payments.

---

### 11. Virtual Agent Authentication Usability Test

`chatbot` `authentication`

|Issue|[#97](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/97)|
|:--|:--|
|Date|2022-03|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|We are releasing an unauthenticated chatbot in Feb 2022 that will act as a new way to access information to the Veterans, and an authenticated version in April 2022, that will provide personalization and features to access private information, such as claims and appeals status. This tests the flow from non authenticated to authentication.|
#### Objectives
* Is the in-chat bot authentication process clear?
* Do users want/need to sign out from the chatbot?
* Do users need a visual indication for having signed in?
* Are users able to easily find the Virtual Agent?
* What do users currently understand what the chatbot can do?
#### Findings
* Users eventually located the Virtual Agent option on the ”Contact Us” VA.gov webpage, but the Agent’s location in the call-out web element was not immediately apparent.
* Users described an ideal location for a Virtual Agent access point on their screens at the “bottom-right.”
* Users also expressed desires for a chat experience that can collapse and minimize or follow the user during their browsing session.
* None of the users noticed the lock icon at first glance. Most users identified being logged in by seeing the “Hector” name in the top right corner of the page.
* Most users expected a blue sign out button to be available within the Virtual Agent. After the initial confusion, users signed out from the navigation bar.
* Users also expressed that after their Virtual Agent interaction, they would explicitly sign out of their profile.
#### Recommendations
* Group the beta testing Virtual Agent access point in a similar manner as other contact channels.
* Position a minimizable, roaming chat experience at bottom-right of browser screen.
* Remove the lock icon in the chat window.
* Add a sign out button as an additional option in actions that the Virtual Agent presents to the user.

---

### 12. VSP, Ask VA - Business, Personal Tabs (IRIS)

`ask va` `education`

|Issue|Not available. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/iris/research/ava/2022-02/research-plan.md).|
|:--|:--|
|Date|2022-03|
|Team|VSP Contact Center|
|Background|This study is being conducted by the VSP Contact Center team. The study follows the Ask VA (AVA) tool, which enables veterans and VA.gov users to submit inquiries digitally. The AVA product team released a new tab function with labels (Business, Personal) in December 2021. The study will provide feedback for this new feature to the AVA product team. This research was done with SCOs (School Certifying Officials) that serve Veterans at higher education institutions. They are primary users of AVA. Participants were sourced through the VA Call Center team.|
#### Objectives
* Document and prioritize any outstanding usability concerns with AVA, including both inquiry submission and the authenticated dashboard.
* Verify the implementation of new dashboard upgrades, and help SCOs and VA employees with handling caseloads in AVA.
#### Findings
* 3 of the 5 participants had initial login issues with ID.me or got errors in Chrome and had to switch to Internet Explorer.
* All were able to locate the Business and Personal tabs after submitting inquiries specific to GI Bill.
* The number of inquiries made by the SCOs could range from 25-50 a month.
* New users had difficulty understanding the function of the Business and Personal tabs.
* SCO users that had 1 month of usage or more did like the auto-sorting of inquiries for their workflow.
* 2 of the participants referenced difficulties their co-workers may face using AVA.
* All recommended a function to find inquiries in their AVA Dashboard faster.
* 3 of the 5 participants had concerns about adjusting their PI data on the Review page before submittal and confusion about how the fields were auto-populating.
* One person mentioned a workflow where they need to print a PDF of their dashboard and/or a specific inquiry for internal filing. This function often doesn’t work in Chrome.
#### Recommendations
* Research onboarding functions or reminders for the dashboard view.
* Tabs can be renamed per SCO preference.
* Audit needed for the beginning of the AVA form regarding inquiry type. One of the participants highlighted specific keywords related to GI Bill that were not in the drop down.

---

### 13. Needs of Spanish Speaking Veterans for the Virtual Agent

`spanish` `accessibility` `chatbot`

|Issue|[#66](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/66)|
|:--|:--|
|Date|2022-01|
|Team|Virtual Agent|
|Background|With the upcoming release of the Virtual Agent chatbot, the needs for internationalization and making available content for veterans that would prefer to use Spanish or other language as a preferred language are unclear. This research is an effort to understand how the needs of this group differ from the English speaking veterans.|
#### Objectives
* How do needs from Spanish speaking Veterans differ from the English speaking Veterans regarding self service through the chatbot?
* How do Spanish speaking Veterans interact with a chatbot?
#### Findings
* Veterans with services available in their preferred language expressed better satisfaction with the VA.
* Veterans with Spanish as preferred language have relied on a third party or acted as support for other Spanish speaking Veterans.
* Information sharing in Spanish is mostly done verbally, with information lost in translation.
* Veterans showed the need for information consistent with previous research, but preferred having it in their preferred language.
* Most important: emergency services, health, general benefits, solving benefits problems.
* Challenges navigating the VA website were: inconsistent language across pages, most resources in Spanish as PDFs, not knowing what to search for.
* Challenges related with interacting in English being: specialized language, time and effort , and comfort of expression.
* Veterans see the Virtual Agent as a guide to navigate the VA.
* Veterans found that with providing them a link it was very time and effort saving.
* Veterans mentioned if the Virtual Agent was in Spanish they would expect the content of -the links to also be in Spanish.
* Veterans would prefer to use it in their preferred language, but would use it in English if it was the only available option.

---

### 14. MCT Virtual Agent Facilities Conversational Design

`chatbot`

|Issue|[#80](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/80)|
|:--|:--|
|Date|2022-01|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking information about VA facilities with a VA.gov chatbot. User research will focus both on the desirability of specific facilities-related features and on the conversational design of these features. Facilities information and content will be based on the content already available on VA.gov and through the Lighthouse API.|
#### Findings
* When searching for nearby VA facilities, users liked seeing multiple options for comparison.
* Users wanted detailed facility information such as address, hours of operation, facility status, and phone numbers during their VA facility search.
* While most participants understood VA.gov’s facility terminology, a few users were confused by the term "VA Health," and did not expect Specialties or Services to be under the "VA Health" option.
* While most participants had their own reliable transportation, they were aware that others might need transportation assistance.
* Users' utterances and information gathering methods vary both by user and their personal use cases. As some users preferred to input their own text, presenting the user with multiple paths to their answer promotes the findability of key information.
* Users were not able to clearly understand the department extension information in the auto-dial format, “555-555-5555,,5555.” Some also said they wanted more information than just the department phone number in the same response.
* Some users were confused or had a hard time finding their desired information when they were redirected to just the top of the facility information page and not directly to the relevant section.
* Many users said that they would search VA facility information on a search engine or website because existing platforms, like Google and VA.gov, already meet their needs.
* Users liked that the Virtual Agent knew their VA Medical Center or Clinic based on their ZIP Code, but were unsure how to update that information in their account if it was out of date.
#### Recommendations
* Display at least two nearby locations with the option to view additional locations if desired.
* Provide full facility information
* Add additional, clarifying examples between parentheses for certain categories, ex. “VA Health (Medical Centers & Clinics).”
* Include information on transportation assistance where available.
* Provide multiple paths to get to the same information. For example, if users are looking for specialty care in their area, let them start by searching for either specialty care or nearby locations first rather than forcing them down a path they may not otherwise want to take.
* When providing phone extensions, display phone number and extension in a clearly-readable format while keeping the hyperlink embedded in that display. Also consider providing a link with additional information.
* Users expected hyperlink experiences to be seamless. Specifically, they expected their chat button selections to route directly toward a solution on the linked webpage.
* When the Virtual Agent is unable to correctly identify the user's current address (i.e., if their contact information on VA.gov is out of date), provide instructions for users to update their profile.
* Be sure to recognize ZIP Code to search for relevant VA facilities and locations as well as city and state or the name of a specific facility.

---

### 15. Virtual Agent Automated Content and Claims Feature Usability Testing

`chatbot`

|Issue|[#45](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/45)|
|:--|:--|
|Date|2021-11|
|Team|Virtual Agent|
|Background|This research was for Veteran preference for drupal content responses, claims feature feedback and to learn other topics Veterans would be interested to engage with the chatbot.|
#### Findings
* Veterans consistently preferred the preview response for Drupal content because it provided just enough context to make them confident that the webpage link would set them down the right path. They appreciated the full response, but overall felt it was too much info in a small space. The info was more digestible after they followed the link.
* When Veterans were allowed to ask any general topic question, the results for a correct response were mixed.
* The Claims feature was viewed very impressively. Veterans felt that they understood the information provided, really liked that the representative was included, and really appreciated the loading text when the bot was making its API call.
* There was some confusion for the “Speak to Agent” button. Some thought it would provide contact info or connect them to their claim representative, others thought it would make a phone call to the VA, while only a couple thought it would connect them to a live agent chat in the same chatbox.

---

### 16. VSP, Ask VA (IRIS)

`ask va`

|Issue|Not available. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/iris/research/ava/2021-07/research-plan.md).|
|:--|:--|
|Date|2021-07|
|Team|VSP Contact Center|
|Background|This study is being conducted by the VSP Contact Center team. The study follows the Ask VA (AVA) tool, which enables veterans and VA.gov users to submit inquiries digitally.|
#### Objectives
* Are users able to submit inquiries successfully and without hindrance?
* Are users able to navigate and access previous inquiries via the authenticated dashboard?
* Do veterans understand how to fill out all of the fields on the inquiry form?
 * Is help text provided in all the appropriate areas?
 * Do users understand which fields are required?
#### Findings
* All participants were able to successfully submit an inquiry
* OMB Burden Language confused multiple users
> "Respondent? Who's the respondent?"
* All participants expressed interest, or preference, in logging in to complete the form
 * Logging in would automatically fill in multiple form fields, and make further contact more streamlined
* Some technical issues remain, though less than previous tests. These include:
 * Confusion around form fields that launch modal windows. A majority of users clicked in the category field and attempted to type. The search icon and state change when field is click confuse people into thinking they can type into the field.
 * Subtopic field conditionally appears though has no content
* Multiple usability concerns were raised, which include:
 * Confusion around the 'Create reply' button on inquiry details page
 * Empty inquiry reply area
 * Users struggled to find their most recent inquiry on the list due to default sorting
* Additional concerns:
 * How to navigate back to full inquiry dashboard form inquiry details page
 * Nested modal windows in inquiry responses
 * Inquiry details page needs increased clarity with heading adjustments and additions
 * Recommended follow-up procedures if reply is overdue
 * Struggles with file attachment portion of the inquiry
 * General concerns regarding content not being plain enough
#### Recommendations
* Link the inquiry number at the confirmation page to details page
* Reduce prominence of 'Start your message without signing in' button on landing page
* Clarity around nuances and differences between SSN, Service Number and DoD ID/EDIPI Number
* Replace the 'search' icon with a different icon on the category field – or use a drop down menu
* Launch the modal window when the user clicks in the field
* Remove 'Create Reply' until a response is available, or conditionally change text to something more relevant like 'Send a message' or 'Leave a comment'
* Change 'Response Inbox' title to 'Inquiry Details'
* Add a link to the response inbox that will take users back to the dashboard
* Consider includingt he file upload on a previous page, or providing a subhead on the review page to call more attention to the field
* Provide a link within the body of the submission that takes you to the dashboard or directly to the inquiry details page
* Inform users as to whether or not they should expect an email confirmation
* If necessary, inform users as to course of action if 5 days have elapsed without a reply
* Use VA.gov fonts and button styles
* Fix spacing issues on mobile

---

### 17. Virtual Agent Inclusive Design interviews

`chabot` `accessibility` `navigation`

|Issue|[#1](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/1)|
|:--|:--|
|Date|2021-06|
|Team|Virtual Agent|
|Background|The virtual agent/chatbot will eventually be hosted on Va.gov. Exact location(s) to be determined. Ultimately, the virtual agent’s goal is to provide responses based on existing Va.gov content to enable and encourage self service behaviors. This project is part of the larger Omnichannel strategy (led by VEO) to provide veterans with seamless access to information.|
#### Findings
* Links in the chat log were not keyboard focused. We validated that this issue occurred and that the links added to the VA chatbot's responses are not reachable by keyboard when navigating through the page with the TAB key. This is a defect 1 status (i.e. the most severe, ‘must fix’ issue) according to Section 508, meaning it needs to be fixed before launching on VA.gov.
* Links were being announced as "messages" or just text and not links. We validated that JAWS and VoiceOver are reading out links in the chatbot responses as "LINK TEXT, message" or just reading out the link text and never saying "link". This is a defect 1 status (i.e. the most severe, ‘must fix’ issue) according to Section 508, meaning it needs to be fixed before launching on VA.gov
* Many of the additional accessibility issues which were less urgent than defect 1 in severity were observed, including the challenge of finding the chatbot on the page in the first place.
 * If one navigates off the chatbot, it is difficult to navigate back onto it, and depends on the participant using VoiceOver’s Form Control menu navigator.
 * For the ‘chatbot text input must have a yellow focus halo when it receives keyboard focus’, we noted the halo appears for the ‘send message’ icon but not for the message input box itself.
* Blind Veterans can differ in how they use technology, including assistive technology.
> “I have to remember to turn off automatic form fields, because the VA website doesn’t say that. It can be inconvenient - used to be the only way to navigate that. [Now] I use the element navigation on a web page [not buttons]. I like to use that, it’s easier for me. Some other vets use the tab key but that gets me nowhere”
* Despite the accessibility challenges participants were eager to use the chatbot and indicated they would want the same feature set (such as authentication) as the non-blind population.

---

### 18. VSP, Ask VA (IRIS)

`ask va` `navigation`

|Issue|Not available. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/iris/research/ava/2021-04/research-plan.md).|
|:--|:--|
|Date|2021-04|
|Team|VSP Contact Center|
|Background|What, if any, changes need to be implemented before the full release of the Ask VA (AVA). Explore topics such as Customer Satisfaction & Trust, Findability and (Task) Service Completion. Testing full AVA experience. Testing the content of the form.|
#### Objectives
* Does AVA provide end users with a user-friendly method of submitting inquiries for issues regarding VA.gov?
* What are end users expectations in regards to inquiry submissions?
* Expectations in regards to: information needed to submit an inquiry, response time, login information, etc?
* Does AVA provide an interface that elicits trust from the end user?
* Is “plain language” utilized throughout the entirety of the AVA application?
#### Findings
* Form findability
  * 4 out of 7 users were able to find a link to ask a question, though the experience was often roundabout and confusing
  * Only 3 participants went straight to the Contact us page
  * Even if users navigate to the Contact us page, it's not guaranteed that they'll find the Ask a question links
  * 2 participants on the Contact us page clicked on the Research and support button and didn't find a link to ask a question
  * If users are seeking to ask a question about a specific topic, they are more likely to navigate to tertiary pages regarding that subject. These pages rarely contain links to asking a question.
* The form is largely self-explanatory; all participants were able to successfully submit an inquiry
* OMB Burden Language confused multiple users
* All participants expressed interest, or preference, in logging in to complete the form
  * Logging in would automatically fill in multiple form fields, and make further contact more streamlined.
* There were multiple technical issues which diminshed the overall usability of the form:
  * Lack of help text around certain form fields
  * Review page does not have a title, nor does it retain conditional display logic
  * Required field indicators are easily overlooked
  * Modal window search inconsistencies: For example, when you search for Loan in the modal, it yields no results despite Home Loan being an option
  * Spacing issues
* Users were unsure of the correct format for various date fields.
* Users were unsure what to put for "Veteran's Service Number," most thought it was their SSN. Other abbreviations caused confusion like DoD ID/EDIPI and SSN.
* Required field indicator was easily overlooked. Design system recommendation was to include "Required" as text alongside the red asterisk.
* Large space at the bottom of form pushed the 'Next' button below the fold for some users.
* Issues on mobile.
#### Recommendations
* Links on the contact us page need increased visibility
* Ask a question links need to be added on internal pages, possibly on a consistent basis
* Address the review page form conditional display issues
* Add help text around specific fields, such as:
 * Veterans Service Number, SSN, DoD ID/EDIPI
 * Clarify required date format for date fields or consider implementing design system date picker
 * Additional context and description for the attachment field
* Resolve the appropriate design system updates (fonts, button, required field display)
* Reduce spacing between form fields and 'Next' button
* Add header and clarifying informatoin to the review page

---

### 19. VA.gov Relaunch (Involved multiple studies)

`information architecture` `navigation`

|Issue|Not available; and this work contains multiple studies. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/tree/master/products/va-gov-relaunch-2018).|
|:--|:--|
|Date|2018|
|Team|DSVA|
|Background|The problem this initiative aimed to solve was that Veterans do not have a single place to find, apply for, and manage their health care and benefits. On Veterans Day of 2018, VA.gov was relaunched with a consolidation of the various VA.gov digital properties (MHV, eBenefits, Vets.gov). User research for these efforts was captured in this [plan](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/va-gov-relaunch-2018/user-research/user-research-plan.md).|
#### Study 1: 'Others' Resources Card Sort
* Our goal was to learn how to organize the "other" resources that don’t fit into the benefit categories.
* We confirmed that there is no clear or consistent way to group and label all the “other” content but the data still show items with the strongest relationship and provide Veteran-focused labels:
 * Account Information / Management
 * About the VA
 * My VA / For Me
 * Most Important (focused on health due to audience)
 * Self Service / Online
* Airborne Hazards and Ordering Hearing Aid Batteries were consistently outliers
#### Study 2: Benefit Lifecycle Card Sort
* Grouped into (1) Explore and Apply, (2) Track and Manage or (3) More from VA
* Organizing benefits around the lifecycle makes sense to Veterans
* Explore & Apply works well for the items we thought fit in that category like “Health Care Eligibility”
* Many Track & Manage cards were consistently sorted by Veterans, but other items including “Request DD-214” don’t fit
* Several items including “Compare GI Bill Benefits” aren’t easily placed in only one category
* More From VA cards had the most inconsistent placement but did not distract Veterans from the benefit lifecycle
* We learned that the benefit lifecycle can work as part of the content strategy but applying it to the content hubs will take finesse
#### Study 3a: Homepage Wireframes v1
* Top Tasks Homepage:
 * Zone 2 focused on the top tasks available to Veterans split between recurring “manage” and one time “apply” boxes
 * Zone 3 listed each benefit category with a simple description and CT
* Benefit Category Homepage:
 * Zone 2 listed the top 4 benefit categories with top tasks listed under “Explore & Apply” or “Track & Manage”
 * Zone 3 showed the remaining benefits with lists of top tasks for each
* 7/10 preferred “Benefit Category” design over “Top Tasks”
* Benefit hubs were confirmed as a good organization method
* Veterans wanted the most popular list in each benefit but were overwhelmed by the number of choices
* Separating top tasks from benefit labels was “distracting”
* Both designs were “clean” but “boring” and needed more images
* Appreciation for the one-click access to top resources
#### Study 3b: Homepage Wireframes v2
* Top Tasks Homepage:
 * Zone 1 focused on the top tasks organized under manage health, track benefits, get records, apply for benefits
 * Zone 2 had the location, crisis line, and sign-in
 * Zone 3 listed each benefit category with a simple description and CTA
* Benefit Category Homepage:
 * Zone 1 had the location, crisis line, and sign-in
 * Zone 2 listed the top 4 benefit categories with top tasks
 * Zone 3 showed the remaining benefits with lists of top tasks for each
* The default mental model for Veterans is benefit category first then task
* Veterans had difficulty finding information using the headings in the top tasks design
* CTA buttons in the top task design (color and placement) worked best
* The layout of the top benefit categories worked well
* Both designs are boring and need more color
* Veterans want the page to be simple and not cluttered
* Veterans want large, clear, text and icons
* One-click access and “above the fold” priority are important to Veterans
* The benefit category is the default mental model for organizing information, but top tasks are why users come to VA.gov.
#### Study 4a: Navigation Tree Test v1
* Veterans struggled to navigate the menu to complete top tasks
* Directness scores indicate that users were confident in their incorrect answers
* The sheer volume of content and number of levels in the menu contributed to the overall poor performance
* Choosing between “Get” and “Manage” benefits continued to distract users
* Top Tasks:
 * Health Care tasks – Both “About VA” and “Find a VA Location” were common incorrect paths
  * For health conditions information – “About VA” was a common path
  * Health tasks mostly scored 4s, ranged 3-5.
 * Disability tasks – Users were looking in the Health hub for “Apply” tasks and in the Records hub for “track and manage” tasks
  * Upload Docs and Add/Remove Dependent scored 2s. Others 4-5.
 * Education tasks – Users frequently chose incorrect “apply” links. Scores ranged 4-5. 
 * Records tasks – “About VA” was a common incorrect path. Scores 3-6.
 * Pension tasks – Disability hub was the most common incorrect path. Scored all 4s.
 * Jobs task – “About VA” was the first misstep for most users but many were also confused by “Get” vs “Manage”. Score 2.
 * Cemetery tasks – Scored 6s, generally good with some distraction by “About VA” and “Pre-Need”.
 * Facility Locator – Scored 9. Listed at the top level of nav.
 * About VA tasks – Scored 2s. Largely done as an info gathering activity, needs more research.
* Recommendations:
 * Simplify the mega menu options by reducing the number of links per section
 * Consolidate the “Apply” entry points in the menu for each benefit
 * Cross-link between the Health, Disability, Pension, and Records hubs for alternative navigation paths
 * Cross-link from the Facility Locator and Facility pages to the Health hub
 * Re-organize the Jobs menu options
 * Discuss “About” Menu top tasks
#### Study 4b: Navigation Tree Test v2
* Our goal was to determine if a simplified mega menu is a reasonable solution to VA.gov
* Health tasks generally performed well
* About VA was a contributing distraction for health tasks (~10%)
* Many Veterans looked in Records for disability management tasks (upload docs, direct deposit, add dependents)
* Health Care and Pension were also commonly visited during disability tasks
* About VA was the only consistent distractor on Education tasks (~28%)
* About VA was the biggest distractor for Veteran ID (31%) and DD-214 (44%)
* Disability was commonly visited when looking for VA Letters (38%)
* About VA distracted from Home Loan COE (36%)
* About VA was a large distractor from Pension tasks
* The other links in the Pension Hub distracted Veterans more than other hubs (81% success rate)
* Most Veterans looked for Find a Job under About VA (62%)
* Veterans looked under About VA for Find a Cemetery (44%)
* Health Care was the most common destination for Veterans Choice Program
* The other About VA categories (Learn, Innovation) were distractors from finding the Public Affairs content
* We may want to consider a term other than “About VA” to help distinguish benefits content from other VA content
* We still have to rely heavily on cross-linking the hubs and redirecting users back from About VA pages to the benefits content
* Each Hub will need additional research to refine the terms used 
#### Study 5 – Preview.va.gov Usability Test
* Veterans liked and understood the benefit categories
* The top tasks boxes drew users attention and they commented on the usefulness of the links
* Homepage layout exposed Veterans to benefits they may not have considered
* Browsing the top navigation worked well in both formats
* Users understood the purpose of the “About VA” tab
* VCL got good reception and emphasis from Veterans
* The top tasks on the homepage worked well but Veterans overlooked the top navigation generally
* The full benefit category list in the middle of the homepage did not catch their attention
* Some users commented that the homepage was “flat” or “boring”
* Users liked the hub page format and were successful browsing the headers, links, and text
* Most users understood that many tasks would require sign-in to complete
* The sign-in alert on the tool landing pages worked well
* We watched across several users as they found multiple routes to key tasks such as Rx Refill
* On desktop, the call to action button was outshined by the left navigation, leading users to mistakenly click the highlighted (current page) link
* The volume of text on the Hub pages may have been overwhelming to some users
* A few users expected to get straight to the sign-in page from the Hubs
#### Study 6: Preview.va.gov Non-VA Vets
* Feedback from non-VA veterans was overwhelmingly positive
* Users appreciated the simplicity and layout of the homepage
* Users generally completed the scenarios, but tasks that were not listed in the “top 4” boxes were much more difficult
* VCL got good reception and emphasis from Veterans
* The top tasks on the homepage worked well but Veterans still tended to overlook the top navigation
* Many Veterans did not scroll down the homepage, even when seeking benefits not in the “top 4” boxes
* These resulted in significantly lower success rates for tasks not listed in the top tasks area (Avg. 54% vs 88% )
* Users emphasized the importance of the VCL
* May need to revisit adding a View All option to the ”top 4” boxes
* Modify the fold location so its apparent to the user that more options exist lower down the page
* Make the top navigation stand-out more
#### Study 7: Preview.va.gov Usability Test 2
* Our goal was to test the full Preview site with Veterans
* Veterans are generally returning to the homepage to accomplish tasks after being logged-in, not the dashboard
* On MHV, users are able to find the most common tasks
* Several Veterans were hesitant to provide their email address and phone number when converting MHV credentials to ID.me
* Most Veterans did not find the VCL through the top banner, they either noticed the button or the footer link
* Veterans had mixed feedback about the “Contact Us” information on the hub pages
* The new left navigation corrects the usability issues found in Study 5
* Veterans were not confused by the multiple sign-in options (MHV, DS Logon, ID.me)
* Open in new tab function failing from the tool landing pages, either because the new tab to MHV/eBN doesn’t open or it gets blocked
* The single sign-on issues with MHV and the new tab usability issues must be fixed before launch
* Split the contact us section into two sections - phone numbers and social media links
* Keep the VCL copy the same do not rely solely on the banner to drive users to that information
* Longer-term the flow to convert an MHV account to ID.me account should be simplified
#### Study 8: Preview.va.gov Authenticated Test
* Our goal was to watch users with accounts work through preview top tasks
* Veterans were able to find the ”Sign In” box to login to their account
* Users were able to complete MHV and eBN tasks from the VA.gov homepage
* MHV and DS Logon users were able to see their dashboard and data on VA.gov
* The ”My VA” and “My Health” tabs are working
* Veterans easily located the drop-down with their name to log out and access settings
* Logging-out on VA.gov is not logging the user out of their MHV account
* Veterans are generally not finding “My VA” and “My Health” in the top right of the page
* Deep links into eBenefits are not useful, users attempting to upload documentation cannot complete task
* Each new tab opening up eBenefits requires user to login again, credential is not being shared across tabs

---

Note: There are other studies that look at the 'one thing per page' pattern which can be [found here](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues?q=is%3Aissue+%22one+thing+per+page%22+).

## Key takeaways

* Ask VA is not currently 508 compliant, accessible for disabled Veterans, usable on mobile or following VA design system standards.
* People expect a chatbot or Ask VA to be available on the page they're currently on, or otherwise on the Contact page. Right now, it's challenging to find, particularly if you're using assistive technology.
* Many people expect chatbots to be able to answer simple, close-ended questions, but for more complex inquiries they prefer to contact a human. However, this does vary, with some people expecting personalized, specific replies from a chatbot, too.
* If people use Ask VA while they're signed in, they expect their information to be leveraged so they save time filling in details about themselves. They also might expect a more specific reply when signed in. Whether or not people will sign in to submit a query, though, varies.
* People lose trust in bots if they misinterpret, their reply is not clear or they can't help. They also worry more about security when interacting with a bot, compared to a human or secure message.
* If a chatbot can't answer a question, people expect to be able to submit a ticket or connect with a human. Or for the chatbot to ask them a clarifying question.
* People expect an immediate reply from a bot and a delayed reply from a live agent. Some people feel this should vary based on urgency and complexity of the query.
* There's a balance between sharing too much information and not enough. In general, being concise and breaking information into chunks works best for people.
* For short forms, a one thing per page approach can be less ideal. But starting with this approach is a recommended practice.
* People are usually satisfied with receiving a link or resource when they ask a query, whether it's a link on VA.gov or elsewhere. Additional consideration needs to be taken so that links are accessible using assistive technology.
* Guided buttons to reply can be helpful and lead to better results – but if you don't see an option that fits, it's unclear what to do next. There may be a need to provide both buttons and the option to type.
* The review page currently causes confusion because people expect to upload a file before they get to the review page, and people may not be clear about how the review page populates and whether they can edit information on it.
* Topics and form fields on Ask VA are not always clear, and including examples could help clarify.
* Some people, like School Certifying Officials (SCOs), submit queries for themselves and for others, and need help organizing and categorizing these in their dashboard.
* After they submit a query, people need to know how long they will have to wait, where your query is being routed, how to find and track progress, and how to follow up if it's taking too long.
* After someone receives an answer, they look for a way to close out the conversation. In addition, some people look to sign out directly from the chatbot.
* There's not currently an accessible way for Veterans to provide feedback on VA.gov through Medallia.
