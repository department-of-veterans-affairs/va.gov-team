# Research plan for Ask VA: Automation concept testing

Ask VA VA.gov Team

Last updated by @tygindraux: February 3, 2025

**Jump ahead to:**
- [Background](#background)
- [Research goals](#research-goals)
- [Methodology](#methodology)
- [Recruitment](#recruitment)
- [Timeline](#timeline)
- [Pilot session](#pilot-session)
- [Research sessions](#research-sessions)
- [Team roles](#team-roles)
- [Approved by](#approved-by)

## Background

Ask VA (AVA) lets Veterans, their family members and other submitters ask VA a question. In 2024, VA received over 500,000 questions through Ask VA. Ask VA includes a form, where submitters share their question with VA, and, a dashboard, where submitters review past questions, read replies from VA and reply back.

After launching on VA.gov, we will focus on making quick, responsive improvements to the product while also bringing partners along on the journey. Our [product outline](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/product/Product%20outline.md) includes more details about Ask VA and [Phase 2 initiatives](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/product/Phase%202%3A%20Initiatives.md) describes our focus from January to March 2025.

### OCTO priorities

This research supports the following OCTO FY25 priority:
- Objective 1: VA’s digital experiences are the easiest and most efficient way to access VA health care and benefits.  

### Veteran journey

Ask VA can support Veterans, their family members, and other submitters at many stages of the Veteran journey. They may use Ask VA when they’re separating through aging.

## Research goals

The key goals of this study are to:

* understand how submitters expect to interact with and benefit from automation when asking VA a question online
* understand whether providing recommendations using automation will make it easier to ask a question or receive help

### Outcome

This research will help us determine how we should use automation to support the submitter experience of Ask VA.

We will develop a clear recommendation for which feature(s) to carry forward and prioritize building.

### Research questions

Understand how submitters expect to interact with and benefit from automation when asking VA a question online:
* Do submitters recognize when something is automated? How does this change their experience either way?
* What are submitters key hopes and fears when it comes to automation?
* Is it important for submitters to know when a recommendation has been made using a data model?
* Are there other ways, besides these concepts, that submitters expect Ask VA to be automated?

Understand whether providing recommendations using automation will make it easier to ask a question or receive help:
* How do these concepts make it easier or more difficult for Veterans to submit a question?
* How do these concepts make it faster or slower for Veterans to submit a question?
* How do these concepts make Veterans likely to send a more or less accurate submission to VA?
* Do people prefer to receive a recommended category, topic or resource list and why?
* Is it helpful to abstract the idea of a category and topic (eg. "We think your question is about ... and relates to ...") or insignificant?
* Will people choose to stop asking their question in favor of accessing other helpful resources when they're suggested?
* Which issues do we foresee with implementing these concepts based on submitters' experiences during testing?

### Hypotheses

1. Inputting your question to begin 'asking a question' through Ask VA is intuitive.
2. It's helpful to be aware of the other options when you confirm if a category or topic suggestion is correct.
3. Figuring out how to use the edit button to update a category, topic or question is clear.
4. If you need to edit the category or topic that's been suggested, it's difficult to choose from a long list of options.
5. It needs to be clear how much information you need to add to your question in order to get a more accurate suggestion.
6. Knowing that a suggestion has been generated using automation can impact how much you trust the suggestion.
7. Data models are not familiar to most people, however, receiving a recommendation based on past questions people have asked is understandable.
8. People will choose to abandon Ask VA in favor of clicking a helpful link to get more information.

## Methodology

This will be a moderated study conducted remotely over Zoom. We will use Figma prototypes with limited interactivity and test on mobile only.

We will present 3 concepts to submitters in varying order to understand how they use and react to them.

- **Concept A: Recommend a category and topic based on a question:** Submitter inputs a question, system recommends a category, submitter edits category or continues with recommendation, system recommends a topic, submitter edits topic or continues with recommendation.
- **Concept B: Ask for a more detailed question to determine category and topic:** Submitter inputs a question, system describes which category and topic it thinks are a good fit, submitter can edit their question if they feel the recommendation should be different, if they don’t reach a successful recommendation, submitter can choose category and topic themselves.
- **Concept C: Provide helpful links so someone can decide whether to continue asking a question:** Submitter inputs a question, system uses question to provide helpful links to other information on VA.gov that may answer their question, submitter can choose to navigate away from asking a question or to continue by selecting their category.

### Research materials

* [Conversation guide](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/design/User%20research/01-2025%20Automation%20concept%20testing/Conversation%20guide.md)
* Prototypes
  * [Prototype A: Recommend a category and topic](https://www.figma.com/proto/ifZqIdl3YRZ7rk3riz7MZN/AVA-Phase-2---Exploration?node-id=117-8174&t=zZCiEN70ehoO9Epu-1&scaling=scale-down&content-scaling=fixed&page-id=117%3A7572&starting-point-node-id=117%3A8174)
  * [Prototype B: Ask for a more detailed question](https://www.figma.com/proto/ifZqIdl3YRZ7rk3riz7MZN/AVA-Phase-2---Exploration?node-id=139-2957&t=Znc7llXZ2zSJhRXO-0&scaling=min-zoom&content-scaling=fixed&page-id=134%3A4903)
  * [Prototype C: Provide helpful links](https://www.figma.com/proto/ifZqIdl3YRZ7rk3riz7MZN/AVA-Phase-2---Exploration?node-id=73-14487&t=Znc7llXZ2zSJhRXO-0&scaling=scale-down&content-scaling=fixed&page-id=73%3A14484&starting-point-node-id=73%3A14487)

## Recruitment

### Recruitment approach

We will work with Perigean to recruit Veterans.

### Recruitment criteria

We will recruit 10 Veterans for a total of 7-8 completed sessions.

For more details about our criteria, refer to our [Recruitment ticket](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/792).

|# of participants|Criteria|
|:--|:--|
|Exactly 10|Are Veterans|
|Exactly 10|Have contacted VA online or over the phone in the past year|
|Exactly 10|Have signed in to VA.gov in the past year|
|**Exactly 10**|**Are willing to join the session from a mobile device**|
|At least 5|Have a cognitive disability or consideration|
|At least 5|Are over 55 years old|
|At least 4|Identify as Black, Asian, Hispanic or Native|
|At least 3|Are rural|
|At least 3|Don't have a degree|
|At least 2|Identify as a gender other than male|
|At least 2|Identify as LGBTQ+|

### Screener questions

1. Have you contacted the VA online or over the phone in the past year? [Yes, no: Must answer Yes to qualify]
2. Have you signed in to VA.gov in the past year? [Yes, no: Must answer Yes to qualify]
3. Are you able to join the Zoom session from a smartphone such as a Samsung Galaxy or iPhone? Any kind of smartphone will work as long as it connects to the internet. [Yes, no: Must answer Yes to qualify]
4. Do you find it difficult to remember or learn new things, focus on a task, or make decisions? We ask this question because we want to make sure that our tools work for people who live with challenges like these.  [Yes, no: At least half of participants must answer Yes to qualify]

## Timeline

|Date|Milestone|
|:--|:--|
|February 4, 2025|Research Review|
|February 10, 2025|Pilot session|
|February 20 - 25, 2025|Research sessions|
|February 20 - 27, 2025|Scrub, store and analyze transcripts|
|February 28 - March 4, 2025|Synthesize findings|
|March 5, 2025|Share insights|
|March 5 - 17, 2025|Support engineering spike|
|March 17, 2025|Make recommendation|

## Pilot session

Perigean does **not** need to set up our pilot session. Tyler will schedule herself.

### Pilot

- Pilot participant: Joe Hall
- Date and time of pilot session: 10-11am on Feb 10th

## Research sessions

- Length of sessions: 1 hour
- Buffer between sessions: 30 minutes
- Maximum sessions per day: 4 sessions

### Availability

We will provide 20 time slots, with the aim to book 10 sessions. Please prioritize filling earlier sessions in the schedule first.

**When Perigean schedules the sessions, we request that they include the session time in the participant's respective time zone (from their address).**

|Date|Timeslots (EST)|
|:--|:--|
|Thursday, February 20|9-10am, 10:30am-11:30am, 12-1pm, 1:30-2:30pm, 3-4pm|
|Friday, February 21|9-10am, 10:30am-11:30am, 12-1pm, 1:30-2:30pm, 3-4pm|
|Monday, February 24|9-10am, 10:30am-11:30am, 12-1pm, 1:30-2:30pm, 3-4pm|
|Tuesday, February 25|9-10am, 10:30am-11:30am, 12-1pm, 1:30-2:30pm, 3-4pm|

## Team roles

* Moderator: Tyler Gindraux (tyler@bluetiger.digital)
* Research guide writing and task development: Tyler Gindraux
* Participant recruiting & screening: Perigean
* Project point of contact: Tyler Gindraux
* Participant for pilot test: Joe Hall (Tyler will schedule pilot session herself.)
* Accessibility specialist: -
* Notetakers: Tyler will add notetakers to the invites herself.
* Observers: Tyler will add observers to the invites herself.

Sessions will be limited to no more than 5 people, including 1 participant, 1 moderator, 1 notetaker, 2 observers.

## Approved by

- Becky Phung, PO on January 30, 2025
- Shane Strassberg, VA Research Ops on February 5, 2025
