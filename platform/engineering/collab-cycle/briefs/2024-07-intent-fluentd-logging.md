# 2024-07 - Architecture Intent - Add Fluentd to Logging Stack

**Product description:** Enable flexible routing of log messages from VA.gov backend services (particularly vets-api) to various destinations according to specific purposes of those log messages: <br/>
* General operational logs to Datadog
* Audit logs to VA's Enterprise Splunk
* Transaction tracing events to Enterprise Event Bus (Kafka)
* (Possibly) Logs with SPI/user identifiers to a secure location compatible with ATO requirements, to allow correlation/analysis against general logs <br/>
* Provide library methods to vets-api developers to make it easy to target logs to different purposes/destinations rather than everything being `Rails.logger.info`.

([Earlier proposal][logging-proposal] with more product description/background)

**UX design description:** No end-user UX

**Frontend changes:** No frontend impact

**Internal API changes:** <br/>
* By default, no change to existing vets-api code. Rails.logger will continue to work and log messages flow to Datadog
* Provide new vets-api library methods to generate log messages with specific semantics. Ultimately these will also result in Rails.logger with the specific tags/metadata needed for Fluentd to filter and route them to the right destination in the right format, and insulate VFS teams from the implementation details of what those tags/formats are. 

**External API changes:** N/A

**Background jobs:** No new background jobs are needed specific to this effort. The logging library API should be available to vets-api-worker as well as vets-api-server.

**Data storage:** No database impact
- Data storage
    + Describe new or modified databases, tables or columns
    + Describe indexes and constraints
    + Identify PII and PHI and where and how it will be stored and processed

**Libraries and dependencies:** Add [fluentd][fluentd] as an infrastructure dependency. Fluentd is approved in the VA TRM, and was previously installed in the VA>gov infrastructure when Loki was used for logging.

**Metrics, logging, observability, alerting:** <br/>
* Add monitoring/alerting for health of Fluentd runtime alongside other infrastructure components
* Add monitoring/alerting for expected rate of log messages flowing to various destinations

**Infrastructure and network changes:** <br/>
* Addition of Fluentd in the logging stack. To realize the most benefit, we want to capture and route logs as they are generated by the vets-api container, not at a later stage such as consuming logs from Datadog where they have already been filtered.
* Network connection between Fluentd and Enterprise Event Bus. The Event Bus team has validated that Fluentd can be connected using that system's auth mechanism (AWS MSK with IAM-based auth).

**Test strategy:** <br/>
* Unit testing for any Ruby utility libraries provided
* Ideally we will test the FluentD configuration via an integration test executed in lower environments although I don't know how realistic it is to programmatically verify log messages showing up in their eventual destinations.

**Rollout plan:** Initial Fluentd deployment can be validated in dev environment with the first pass being that all logs continue to flow to Datadog. Introduce additional routing rules iteratively. 

**Internal administration tasks:** 
* As usage of this evolves it may be necessary to tweak the FLuentD agent configuration - e.g. to update or add log filters/patterns for forwarding to Event Bus. These should optimally be defined in source control-managed configuration and deployed automatically. 


## Security Checklist Commentary

**PII and PHI handling**
* This solution *does* propose to log PII including ICNs and other veteran identifiers associated with various submissions/transactions.
* However, I believe the intended outcome is that no PII or PHI may be logged **to Datadog** due to its ATO.
* This solution can enable selective logging of PII to other destinations like Kafka and Splunk that are approved to house PII (though it should still be done thoughtfully).
* In particular, if library methods are provided that explicitly express the intent of "I am logging PII" (to Datadog/Splunk) then the log payload can be tagged as having PII and explicitly excluded from Datadog.

**Data retention**
* FluentD itself retains no data.
* The upstream destinations for transaction data (Kafka, CXI data warehouse) define their own data retention policies per their ATOs.

**Data encryption**
* The Enterprise Event Bus Kafka instance does not allow plaintext connections.

**Authentication and authorization**
* The Enterprise Event Bus Kafka instance uses MSK IAM authentication, which combines use of AWS IAM roles with OAuth bearer tokens for client authentication/authorization.
* No static API keys 

<!-- links -->
[logging-proposal]: https://dvagov-my.sharepoint.com/:w:/r/personal/patrick_vinograd_va_gov/_layouts/15/Doc.aspx?sourcedoc=%7Bb09703bb-802b-4a1b-9ec6-3087ab7b5766%7D&action=view&wdAccPdf=0&wdparaid=143C6D6D
[fluentd]: https://www.fluentd.org/
