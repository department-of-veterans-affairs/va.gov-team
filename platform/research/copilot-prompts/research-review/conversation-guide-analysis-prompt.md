# Reusable Prompt for Analyzing a Conversation Guide Against a Research Plan

This reusable prompt is intended to guide researchers in evaluating whether a conversation guide effectively supports the goals and hypotheses set forth in a research plan. It ensures that GitHub Copilot can provide a thorough analysis and actionable recommendations for improving the guide.

By using this reusable prompt, researchers can efficiently evaluate conversation guides and ensure alignment with their research objectives, leading to more effective studies and actionable insights.

---

## **Purpose of the Prompt**
The prompt is designed to:
1. Assess whether the conversation guide aligns with the goals and hypotheses in the research plan.
2. Identify strengths and weaknesses in the guide relative to the research objectives.
3. Provide actionable suggestions for improving the guide to better achieve the research goals.

---

## **Key Considerations**
- Ensure that all files and links provided to Copilot are up-to-date and relevant.
- Use specific and detailed language in your request to ensure Copilot’s response is comprehensive.
- Consider including a summary of the research plan’s goals and hypotheses to provide context for the analysis.

---

## **Recommended Prompt for Reuse**
Below is the recommended reusable prompt for requesting an analysis:

```
Analyze this conversation guide against the research plan found here: [Link to Research Plan]. 

- Provide clear guidance on whether this conversation guide helps achieve the research plan's goals and answer its hypotheses. 
- Identify specific areas where the guide excels, as well as gaps or opportunities for improvement. 

- Provide actionable suggestions for adjustments, such as adding questions, refining tasks, or testing specific hypotheses. 
- Ensure your response includes insights on accessibility, emotional and cognitive load, and alignment with mental models.
```

---

## **How to Use the Prompt in GitHub Copilot Chat**
1. **Prepare Relevant Materials:**
   - Ensure you have both the conversation guide and the research plan available in the repository or as external links.

2. **Initiate the Prompt:**
   - Start by pasting the reusable prompt into the GitHub Copilot chat interface.
   - Modify the context-specific details, such as filenames, repository paths, or goals, to suit the specific conversation guide and research plan you are analyzing.

3. **Interpret Copilot’s Response:**
   Review Copilot's analysis for:
   - Alignment of the conversation guide with research goals.
   - Coverage of hypotheses through specific tasks or prompts.
   - Suggestions for enhancements, such as additional questions or tasks.
   - Identification of gaps or areas for improvement (e.g., accessibility, cognitive load, mental models).

4. **Iterate:**
   - If Copilot’s response is insufficient or unclear, refine your prompt for more specific insights.
   - Here are further questions you could ask Copilot to refine or deepen its analysis of a conversation guide against a research plan:

     **Deepening Alignment with Research Goals**
     - "Does this conversation guide sufficiently address each research goal outlined in the research plan? If not, which goals are under-addressed?"
     - "Are there any research goals or hypotheses that are not reflected in the tasks or questions in the guide?"

     **Enhancing Usability Testing**
     - "What additional usability tasks could be added to the guide to better evaluate user comprehension?"
     - "Are there any critical usability issues that this guide might fail to uncover based on its current structure?"

     **Improving Accessibility**
     - "How could this guide better assess the accessibility of the pages or forms for users with assistive technologies?"
     - "Does the guide include tasks or prompts to ensure inclusivity for participants with cognitive or visual considerations?"

     **Optimizing Participant Feedback**
     - "What additional questions could be added to encourage participants to share more detailed feedback?"
     - "Are there follow-up questions that could help clarify participants' ratings or initial responses?"

     **Exploring Emotional & Cognitive Load**
     - "What questions could be added to better understand the emotional and cognitive burden participants experience during the tasks?"
     - "How can we probe participants' confidence levels when completing tasks in the guide?"

     **Validating Hypotheses**
     - "Does the guide include sufficient tasks or questions to test all the hypotheses in the research plan?"
     - "What additional tasks or prompts could be added to explore Hypothesis [X] in more detail?"

     **Expanding Mental Model Exploration**
     - "How could this guide better explore participants’ preexisting mental models about the process?"
     - "Are there reflective questions that could help uncover how participants' expectations align with their actual experience?"

     **Testing Variability in User Journeys**
     - "Does the guide test alternative navigation pathways effectively? If not, how could it be improved?"
     - "What tasks could be added to understand how users might arrive at the relevant pages or forms starting from different entry points?"

     **General Refinement**
     - "Are there any redundant or unclear questions in this guide that could be revised or removed?"
     - "What elements of the guide could be streamlined to make sessions more efficient while still gathering the necessary insights?"

     ***By asking these iterative questions, you can refine the conversation guide to ensure a comprehensive and effective evaluation of the research goals and hypotheses.***







