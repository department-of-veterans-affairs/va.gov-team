---
title: Evidence Request Study Research Findings
product: Claim Status Tool, Benefits
team: BMT-1
office: Office of the CTO - Digital Experience (OCTO-DE)
date: 2025-10-04
researchers:
  - Kat Brinkley
  - Dillon Hawes
research_goals:
  - 1. Evaluate Veterans’ comprehension of the evidence requests
  - 2. Assess the effectiveness of the new content structure
  - 3. Assess Veterans’ ability to navigate/locate features and content that support evidence requests
methodology:
  - "Moderated, structured and remote user interviews"
  - "Method 2"
devices_used:
    desktop: X
    tablet: X
    smartphone: X
participants_total: 9
demographics:
  veterans: X
  age:
    "55-64": X (50%)
    unknown: X
  education:
    n/a
  location:
    n/a
  race:
    n/a
  disability:
    n/a
key_findings:
  - "Finding 1"
  - "Finding 2"
  # etc.
recommendations:
  - "Recommendation 1"
  - "Recommendation 2"
outcomes:
  user: "Desired user outcome"
  business: "Desired business outcome"
further_research_needed:
  - "Breadcrumbs across VA.gov"
synthesis_tools_used:
  - "Mural"
  - "Affinity mapping"
  - "Data matrix spreadsheet"
---

# Evidence Request Study Research Findings 

**Office of the CTO - Digital Experience (OCTO-DE), Benefits Claim Status Tool, BMT-1**

**Date:** 04/10/2025

**Contacts:** Kat Brinkley, Dillon Hawes

**[Research Readout (PDF)]()**  

> [!TIP] 
> Add "user-content-" in front of each link generated by Markdown in order to move the focus correctly for keyboard navigation.

**Jump to:**
- [Hypotheses and conclusions](#user-content-hypotheses-and-conclusions)
- [Key findings](#user-content-key-findings)
- [Recommendations](#user-content-recommendations)
- [Product User and Business Outcomes](#user-content-product-user-and-business-outcomes)
- [Key Performance Indicators](#user-content-key-performance-indicators)
- [Next Steps](#user-content-next-steps)
- [Further research needed](#user-content-further-research-needed)
- [Appendix](#user-content-appendix)
- [Research participants](#user-content-research-participants)

## Research Goals
1. Evaluate Veterans’ comprehension of evidence requests
2. Assess the effectiveness of the new content structure
3. Assess Veterans’ ability to navigate/locate features and content that support evidence requests

When Veterans need to check on the status of their VA claims, decision reviews, or appeals, they use the Claim Status Tool to stay updated on these important steps. This supports the following moments:
- Taking Care of Myself (e.g., managing ongoing disability claims and evidence submission)

## Research Questions
1. How do Veterans currently comprehend evidence requests?
  - Do Veterans understand what VA is asking them to provide in specific evidence requests?
  - How effectively can Veterans understand what action they need to take?  
2. How effective is the new content structure?
  - Do the headings and ever-present content help Veterans understand actions they can take, even when there’s default API content present?
  - Do participants find some response options more difficult or confusing than others 
3. Are Veterans currently able to navigate/locate features and content that support evidence requests?
- How do Veterans navigate the context surrounding the evdence request submission?


## Methodology 

**Moderated semi-structured interviews:** Users were sent a Zoom link with instructions on how to join and share their screen. The user will log into staging.VA.gov and interact with the Claims Status Tool using a test user account containing the necessary claims and evidence requests. Testing will be conducted using the staging environment of the claim status tool, with 2 user profiles that are customized with the requests touched upon in the study. Participants will complete a series of tasks related to evidence requests, and the interviewer will observe their natural flow and ask questions about their experience. Data will be aggregated and synthesized to analyze emergent themes and main findings.

**Staging URL**
- https://staging.va.gov/claim-or-appeal-status/

**Test User Accounts**
- vets.gov.user+64@gmail.com
- vets.gov.user+150@gmail.com



## Hypotheses and Conclusions

**1. Claimants are unsure what they are being asked to provide for an evidence request. When we offer plain language explanations and descriptions of the actions they need to take, along with hyperlinks, claimants' confidence and trust are increased.**
- **Likely True**
- In this study, we found that due to overload of content, confusing abbreviations or language, and challenges with interacting with forms to submit evidence are some examples that caused participants confusing. Additionally, we heard from some users that despite the confusing abbreviations, they appreciate seeing the third party request even when there is no action on their part due to its transparency in an effort to keep the Veteran updated, increasing trust. (this content is already being iterated on)
 
**2. Claimants have concerns about whether VA is taking sufficient action on their claims. Understanding the requests that are being made of 3rd parties can reduce those concerns. However, when that information is unintelligible, it raises those concerns.**
- **Likely True**
- In this study, the users that were able to decipher the abbreviated language in the third party request was unfazed by the language, and generally had a positive understanding of the third party request. However, for participants less familiar with VA language and abbreviations, they reacted with much more frustration at the fact that these items weren't spelled out, giving them an overall negative impression of the structure of this request.



## Key Findings

> [!TIP] 
> Write findings as stand-alone insights that are easy to scan. For example:  
> - "Most participants used the search field to locate forms, often searching for 'veteran health.'"  
> - "Participants struggled with the secondary caregiver section on the form."  

[Example Key Findings](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/find-a-va-form/initiatives/2021-post-mvp-releases/research/research-findings.md#key-findings)

1. Overall, almost 80% of users understood the goals of each evidence request and also were able to complete them
2. Participants expected some confirmation that an evidence request was completed, particularly for Direct Deposit
3. 8/9 participants had little to no difficulty in understanding the request to provide medical exposure documentation at the beginning of the task, some users experienced frustration and challenges around how to actually fill out and submit their responses to complete the evidence request, struggling with how to submit and navigating across pages
4. Participants prefer transparency, including spelling out abbreviations, keeping them updated on third party requests, and each evidence request being kept simple and clear.
5. Consistent across all 4 tasks, participants frequently requested less words on the page and clearer action items, as well as less repetition and redundancy of content surrounding the evidence requests
6. Participants expected the most important call-to-action tasks, most useful features, and “Next Steps” to be first and above informational content
7. Most participants were familiar with the process of downloading, scanning back in and uploading the PDF version of documents, but many reported challenges or frustrations with the process
8. When a participant was familiar with or understood the function of the Online Tool, it was their preferred choice of document submission over PDFs.
9. Participants experienced a range of challenges with forms, from identifying the correct form, downloading and saving the form in an accessible location, actually filling out the form, and navigating their way back to the upload page to complete the request
10. Navigation presented some challenges for users, including navigating across pages and domains of VA.gov to find documents they needed, understanding where they were in the tool, and using breadcrumbs.




# Details of Findings 

### Evidence Request Comprehension

#### 1. 
- describe
- _Supporting data:_

**Areas of Opportunity:**
- 
  - _Supporting data:_



---

## Additional Insights
*Include insights that do not represent patterns but are still valuable.*  
> **TIP:** These could be powerful user comments or unexpected issues worth noting


## Recommendations

*Summarize actionable recommendations based on findings.*  

1. **Recommendation:** [Insert action]  
   - _Supporting evidence: [Insert data]_  
2. **Recommendation:** [Insert action]  
   - _Supporting evidence: [Insert data]_

## Product User and Business Outcomes

*Explain how findings and recommendations align with the product's goals.*

> [!NOTE] 
> Refer back to your Product Outline. 

### Desired User Outcome 
This research supports our desired user outcome by....
 
### Desired Business Outcome
This research supports our desired business outcome by....


## Key Performance Indicators

*Explain how findings will support KPI measurement.*  

> [!NOTE]
> Refer back to your Product Outline. 

### KPI 1
This research supports measurement of this KPI by....


## Next Steps

*Outline immediate actions based on findings, including owners if applicable.*  


## Further research needed

*Identify gaps in the current study and areas requiring additional investigation––such as demographics that were not included in this study.* 


## Appendix

### Research documents
- [Product Outline](link here)
- [Research plan](link here)
- [Conversation guide](link here)
- [Interview transcripts](link here)

### Tools used for Synthesis

*List tools or techniques used, e.g., Mural, affinity mapping.*  
  
### Pages and applications used

*Link to prototypes or pages tested during the study.*  


### Other supporting documents created

*Include links to additional materials, e.g., personas, user flows.*  


### Secondary research

*Include any relevant secondary research, e.g., web analytics, SME interviews.*  

### Research participants 
_Complete the demographic info below using information from the Perigean recruitment survey. For those items where you didn't have participants, please mark with "0". You can use "unknown" if you aren't sure if your participants had a characteristic._ 

[Example Research participants](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/teams/digital-experience/ADE/research/2025-05-save-in-progress/research-findings.md#research-participants)

#### Recruitment criteria

_If you had specific criteria that you recruited for, use this space to explain what those were along with other information you feel would be important to understanding your participants._

#### Demographics 

We talked to **x participants.**

Audience segment:
* Veterans: x 
* Caregivers: x 
* Family members of a Veteran: x  


Gender:
* Male: x 
* Female: x 


LGBTQ+:
* Transgender: x 
* Nonbinary, gender fluid, gender queer, Two-Spirit (Indigenous only), or another gender beyond man or woman: x
* Gay, lesbian, or bisexual: x


Devices used during study: 
* Desktop: x 
* Tablet: x 
* Smart phone: x 
* Assistive Technology: x


Age:
* 25-34: x
* 35-44: x
* 45-54: x
* 55-64: x
* 65+: x
* Unknown: x


Education:
* High school degree or equivalent: x
* Some college (no degree): x
* Associate's degree, trade certificate or vocational training: x
* Bachelor's degree: x
* Master's degree: x
* Doctorate degree: x
* Unknown: x


Geographic location:
* Urban: x
* Rural: x
* Unknown: x


Race:
* White: x
* Black: x
* Hispanic: x
* Biracial: x
* Asian: x
* Native: x


Disability and Assistive Technology (AT):
* Cognitive: x
* AT beginner: x
* AT advanced user: x
* Desktop screen reader: x
* Mobile screen reader: x
* Magnification/Zoom: x
* [Speech Input Technology](https://www.w3.org/WAI/perspective-videos/voice/) like Siri/Dragon Naturally Speaking: x
* Hearing aids: x
* Sighted keyboard: x
* Captions: x


#### Underserved groups we haven’t talked to 
> [!NOTE]
_Complete the [VA recruitment checker for marginalized Veteran groups](https://docs.google.com/spreadsheets/d/1pq7TSHZonfpzAQBJj6B2geGHlNUwZEs4DzEvxcRgu0o/edit#gid=1221033726):_
> 1. Duplicate the ***Template*** worksheet
> 1. Enter your participant information **(see the *Template Instructions* worksheet for details)**
> 1. Make a screenshot of the cells that you want to share and paste it into this report below
> 1. Generate an accessible version of those cells using Github Copilot Chat:
>    - Start a new Github Copilot chat
>    - Enter: "I want to convert these spreadsheet cells into a table in markdown:" 
>    - Copy and paste the cells from the recruitment checker spreadsheet that you've filled in
>    - Copy the resulting markdown table by clicking the copy icon in the Copilot chat, and paste it into this report below 
>    - (If Copilot returns an error, try using a different AI model, such as "Claude Sonnet 3.7 Thinking")

This research does not include the perspectives of the following marginalized Veteran groups:
_List all groups in red from the spreadsheet_
* Group 1
* Group 2
* Group 3

➡️ _[insert screenshot of completed recruitment checker in the format below]_

![Table of underserved groups of Veterans showing how many of each were in this study as compared to target numbers. Data available in the table below this image](link - add image to github folder and link here with .png)

#### A more accessible version of the table in the above image

### Recruitment of underserved groups in [Study name]

➡️ _[paste markdown table of completed recruitment checker from Github Copilot chat]_
