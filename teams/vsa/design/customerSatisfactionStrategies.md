# Strategies to Measure Customer Satisfaction
Shawna Hein, VSA Design Lead

Note that the strategies outlined below are not stand-alone strategies. Several of them can be combined to come up with our overarching customer satisfaction strategy.

## Problems We’re Trying to Solve
* How do we know we’re focusing on the correct features when it comes to user needs?
* How do we know we’re “succeeding” in improving experiences for users?
* How can we get a more timely / clearer picture of user flows, where they start and end, and hiccups along the way?
* We have 6 teams that are being treated as “unique space”/seperate products” even though they are not working on completely unique products / flows 
    * How do we “unify the team” so everyone feels like they are working towards common goals and talk to each other more about potentially overlapping initiatives?

## Strategies to Measure Customer Satisfaction
### Top Task Identification
The strategy here is to:
1. Identify our users’ highest priority tasks / priorities
2. Measure how well we currently are doing on these tasks
3. Take periodic measurements on these same top tasks to see if we are improving

Step 2 can be done in a variety of ways, some of which are outlined later in this document.

To identify the highest priority tasks, it’s recommended to:
1. Engage the entire organization in a process of gathering customers’ tasks.
2. Work with key stakeholders to come up with a short list of these tasks.
3. Get a representative sample of customers to vote on their top tasks.
4. Create a prioritized table of tasks, starting from the task with the highest number of votes down to the one with the lowest number of votes.

This can be done for the entire product as a whole, as well as for specific areas, e.g. “Health Care.”

Resources
https://www.uxmatters.com/mt/archives/2018/02/measuring-the-roi-for-ux-in-an-enterprise-organization-part-1.php

### Baseline Usability Study
In order to get a handle on how well we’re currently doing on top tasks, a baseline usability study can be run.  Although the typical usability study is fairly qualitative, metrics can be added to make things a bit easier to measure. For example, we could keep track of:
1. *Number of assists and failures* - this is the number of times a moderator had to “help” or “prompt” the user in order for the user to complete the task.
2. *Time on task* - although this can be hard to measure, we could get a basic idea of how long it would take a user to complete each task
3. *The participants’ “usability score”* as determined by a strategy like [Magnitude Estimation Testing](https://journals.sagepub.com/doi/abs/10.1177/154193120304700406?journalCode=proe). This involves every participant doing their own baseline task, creating their own metric scale, then measuring each task using their scale.
4. *The customer “subjective mental effort score”* asking the users a question after a task to gauge how much “mental effort” it took them, instead of, say, “delight.”  [research here](https://measuringu.com/papers/Sauro_Dumas_CHI2009.pdf)

If possible, an unmoderated study could also be considered if we’re looking for a large volume of users and think the tasks could be completed without moderation.

### Help Desk Ticket Analysis
Depending on how help desk tickets are managed and tagged, analyzing these tickets can be a good way to gain metrics on how a particular topic is doing usability-wise. The volume of tickets associated with each issue should be going down if the UX is improving.

In some cases, it’s possible to work with the help desk to introduce new tags that coincide with things like the “top flows.”

### Site Analytics
Site analytics can get us some metrics like paths users follow, when people drop off in flows, etc. These are useful but should always be paired with some strategy that can get at “why” these things are happening.

### On Site Intercepts
On site intercepts can be used for key points in flows where we feel like we really want to get “in the moment” feedback or thoughts from a user. These should be used strategically and sparingly, since every intercept can be “annoying” for users.  These should also have no more than a few questions on the popup/modal.  

Another option is to have an “always there” feedback link that is visible and called out for particular flows, but not hijacking the users’ flow.

### One-Off Satisfaction Forms
Similar to intercepts, These forms are typically linked to at the end of a specific flow or task, in order to get “in the moment” feedback from someone right after they’ve gone through something. 
